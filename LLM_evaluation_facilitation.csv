Date,Title,Authors,Venue ,Field,Abstract,Citations by February 2025
2024,"Cooperation, Competition, and Maliciousness: LLM-Stakeholders Interactive Negotiation ","Sahar Abdelnabi, Amr Gomaa, Sarath Sivaprasad, Lea Schönherr, Mario Fritz",NeurIPS,Computer Science,"There is an growing interest in using Large Language Models (LLMs) in multi-agent systems to tackle interactive real-world tasks that require effective collaboration and assessing complex situations. Yet, we still have a limited understanding of LLMs' communication and decision-making abilities in multi-agent setups. The fundamental task of negotiation spans many key features of communication, such as cooperation, competition, and manipulation potentials. Thus, we propose using scorable negotiation to evaluate LLMs. We create a testbed of complex multi-agent, multi-issue, and semantically rich negotiation games. To reach an agreement, agents must have strong arithmetic, inference, exploration, and planning capabilities while integrating them in a dynamic and multi-turn setup. We propose multiple metrics to rigorously quantify agents' performance and alignment with the assigned role. We provide procedures to create new games and increase games' difficulty to have an evolving benchmark. Importantly, we evaluate critical safety aspects such as the interaction dynamics between agents influenced by greedy and adversarial players. Our benchmark is highly challenging; GPT-3.5 and small models mostly fail, and GPT-4 and SoTA large models (e.g., Llama-3 70b) still underperform.",3
2023,Using large language models to simulate multiple humans and replicate human subject studies,"Gati Aher, Rosa I. Arriaga, Adam Tauman Kalai",ICML,Computer Science,"We introduce a new type of test, called a Turing Experiment (TE), for evaluating to what extent a given language model, such as GPT models, can simulate different aspects of human behavior. A TE can also reveal consistent distortions in a language model's simulation of a specific human behavior. Unlike the Turing Test, which involves simulating a single arbitrary individual, a TE requires simulating a representative sample of participants in human subject research. We carry out TEs that attempt to replicate well-established findings from prior studies. We design a methodology for simulating TEs and illustrate its use to compare how well different language models are able to reproduce classic economic, psycholinguistic, and social psychology experiments: Ultimatum Game, Garden Path Sentences, Milgram Shock Experiment, and Wisdom of Crowds. In the first three TEs, the existing findings were replicated using recent models, while the last TE reveals a ""hyper-accuracy distortion"" present in some language models (including ChatGPT and GPT-4), which could affect downstream applications in education and the arts.",47
2018,Modeling Deliberative Argumentation Strategies on Wikipedia,"Khalid Al-Khatib, Henning Wachsmuth, Kevin Lang, Jakob Herpel, Matthias Hagen, Benno Stein",ACL,NLP,"This paper studies how the argumentation strategies of participants in deliberative discussions can be supported computationally. Our ultimate goal is to predict the best next deliberative move of each participant. In this paper, we present a model for deliberative discussions and we illustrate its operationalization. Previous models have been built manually based on a small set of discussions, resulting in a level of abstraction that is not suitable for move recommendation. In contrast, we derive our model statistically from several types of metadata that can be used for move description. Applied to six million discussions from Wikipedia talk pages, our approach results in a model with 13 categories along three dimensions: discourse acts, argumentative relations, and frames. On this basis, we automatically generate a corpus with about 200,000 turns, labeled for the 13 categories. We then operationalize the model with three supervised classifiers and provide evidence that the proposed categories can be predicted.",15
2024,A Hybrid Human-AI Approach for Argument Map Creation From Transcripts,"Lucas Anastasiou, Anna De Liddo",Workshop on Language-driven Deliberation Technology,NLP,"In order to overcome challenges of traditional deliberation approaches that often silo information exchange between synchronous and asynchronous modes therefore hindering effective deliberation, we present a hybrid framework combining Large Language Models (LLMs) and human-in-the-loop curation to generate argument maps from deliberation transcripts. This approach aims to enhance the efficiency and quality of the generated argument maps, promote transparency, and connect the asynchronous and synchronous deliberation modes. Finally, we outline a realistic deliberation scenario where this process can be successfully integrated.",0
2010,Online moderation of synchronous e-argumentation,Christa S. C. Asterhan & Baruch B. Schwarz ,International Journal of Computer-Supported Collaborative Learning ,Computational Social Science,"In this paper, we present findings on moderation of synchronous, small-group argumentation in blended, co-located learning environments. Drawing on findings from the literature on human facilitation of dialogue in face-to-face settings, we first elaborate on the potential promise of this new practice. However, little is known about what constitutes effective human facilitation in synchronous e-discussions. A multi-method exploratory approach was then adopted to provide first insights into some of the difficulties and characteristics of moderation in these settings. To this end, we focused on (1) students’ perspectives on what constitutes effective e-moderation of synchronous peer argumentation in classrooms and (2) the relations between characteristics of actual and perceived moderation effectiveness. The analyses presented in this paper reveal that the role of the e-moderator in synchronous peer discussions is a complex one and that expectations from e-moderators seem at times even contradictory. Also, comparisons with findings on moderation in other communication formats (e.g., asynchronous, face-to-face) show that insights on effective instructional practices in these formats cannot be simply transferred to synchronous communication formats. We close this paper by briefly describing a tool that provides real-time support for e-moderators of synchronous group discussions, and whose development had been sparked by these findings in a further cycle of our design research program. Several questions and hypotheses are articulated to be investigated in future research, both with these new tools and in general.",10
1962,How to do things with words,J. L. Austin,Oxford University Press,"Linguistics, Philosophy","Austin's (1962) How to Do Things with Words is a slim monograph, an initial William James' Lecture delivered in 1955 at Harvard University, which explores in a series of chapters the assumptions philosophers of language and grammarians make of words, especially, statements and sentences, and the underlying contours of differences and similarities between them. Much of the interest in the two concepts by the earliest philosophers, however, attempts to provide a suitable description of what a statement is or is not and what a sentence is or is not; it attempts to account for what statements are used for or what sentences are used for.",
2024,Persistent interaction patterns across social media platforms and over time,"Michele Avalle, Niccolò Di Marco, Gabriele Etta, Emanuele Sangiorgio, Shayan Alipour, Anita Bonetti, Lorenzo Alvisi, Antonio Scala, Andrea Baronchelli, Matteo Cinelli & Walter Quattrociocchi ",Nature,Computational Social Science,"Growing concern surrounds the impact of social media platforms on public discourse1,2,3,4 and their influence on social dynamics5,6,7,8,9, especially in the context of toxicity10,11,12. Here, to better understand these phenomena, we use a comparative approach to isolate human behavioural patterns across multiple social media platforms. In particular, we analyse conversations in different online communities, focusing on identifying consistent patterns of toxic content. Drawing from an extensive dataset that spans eight platforms over 34 years—from Usenet to contemporary social media—our findings show consistent conversation patterns and user behaviour, irrespective of the platform, topic or time. Notably, although long conversations consistently exhibit higher toxicity, toxic language does not invariably discourage people from participating in a conversation, and toxicity does not necessarily escalate as discussions evolve. Our analysis suggests that debates and contrasting sentiments among users significantly contribute to more intense and hostile discussions. Moreover, the persistence of these patterns across three decades, despite changes in platforms and societal norms, underscores the pivotal role of human behaviour in shaping online discourse.",51
2023,Enabling Classifiers to Make Judgements Explicitly Aligned with Human Values,"Yejin Bang, Tiezheng Yu, Andrea Madotto, Zhaojiang Lin, Mona Diab, Pascale Fung",Workshop on Trustworthy Natural Language Processing ,NLP,"Many NLP classification tasks, such as sexism/racism detection or toxicity detection, are based on human values. Yet, human values can vary under diverse cultural conditions. Therefore, we introduce a framework for value-aligned classification that performs prediction based on explicitly written human values in the command. Along with the task, we propose a practical approach that distills value-aligned knowledge from large-scale language models (LLMs) to construct value-aligned classifiers in two steps. First, we generate value-aligned training data from LLMs by prompt-based few-shot learning. Next, we fine-tune smaller classification models with the generated data for the task. Empirical results show that our VA-Models surpass multiple baselines by at least 15.56% on the F1-score, including few-shot learning with OPT-175B and existing text augmentation methods. We suggest that using classifiers with explicit human value input improves both inclusivity & explainability in AI.",9
2005,Modeling local coherence: An entity-based approach,"Regina Barzilay, Mirella Lapata",ACL,NLP,"This article proposes a novel framework for representing and measuring local coherence. Central
to this approach is the entity-grid representation of discourse, which captures patterns of entity
distribution in a text. The algorithm introduced in the article automatically abstracts a text
into a set of entity transition sequences and records distributional, syntactic, and referential
information about discourse entities. We re-conceptualize coherence assessment as a learning
task and show that our entity-based representation is well-suited for ranking-based generation
and text classification tasks. Using the proposed representation, we achieve good performance on
text ordering, summary coherence evaluation, and readability assessment",993
2021,Understanding Dialogue: Language Use and Social Interaction,Rachel Bawden,Computational Linguistics,NLP,"Understanding Dialogue: Language Use and Social Interaction represents a departure from
classic theories in psycholinguistics and cognitive sciences; instead of taking as a starting point the isolated speech of an individual that can be extended to accommodate
dialogue, a primary focus is put on developing a model adapted to dialogue itself,
bearing in mind important aspects of dialogue as an activity with a heavily cooperative component. As a researcher of natural language processing with a background in
linguistics, I find highly intriguing the possibilities provided by the dialogue model
presented. Although the book does not itself touch upon the potential for automated
dialogue, I am inevitably writing this review from the point of view of a computational
linguist with these aspects in mind.
Building on numerous previous works, including many of the authors’ own studies
and theories, Understanding Dialogue presents the shared workspace framework, a
framework for understanding not just dialogue but cooperative activities in general, of
which dialogue is viewed as a subtype. Based on Bratman’s (1992) concept of shared cooperative activity, the framework provides a joint environment with which interlocutors
can interact, both by contributing to the space (with actions or utterances for example),
and by perceiving and processing their own or the other participants’ productions. The
authors do not limit their work to linguistic communication: Many of their examples,
particularly at the beginning of the book, are non-linguistic (e.g., hand shaking, dancing
a tango, playing singles tennis); others are primarily physical, but will most likely also
involve linguistic communication (such as jointly constructing flat-pack furniture); and
others are purely linguistic (e.g., suggesting which restaurant to go to for lunch).
The notion of alignment is highly important to this framework both from a linguistic
and non-linguistic perspective, and is one of the main inspirations of the book, having
previously been presented in Toward a Mechanistic Theory of Dialogue by the same authors. As individuals interact via the joint space, alignment concerns the equivalence
in their representations at a conceptual level, with respect to their goals and relevant
props in the shared environment (dialogue model alignment) and linguistic representations shared in the workspace (linguistic alignment). Roughly speaking, in this second
(linguistic) case, this may for instance correspond to whether or not the individuals
have the same representation of the utterance in terms of phonetics (were the sounds
perceived correctly?) or in terms of lexical semantics (do they understand the same reference by the word uttered?). From here can be explained a number of different dialogue",172
2024,"Sensitivity, Performance, Robustness: Deconstructing the Effect of Sociodemographic Prompting","Tilman Beck, Hendrik Schuff, Anne Lauscher, Iryna Gurevych",EACL,NLP,"Annotators’ sociodemographic backgrounds (i.e., the individual compositions of their gender, age, educational background, etc.) have a strong impact on their decisions when working on subjective NLP tasks, such as toxic language detection. Often, heterogeneous backgrounds result in high disagreements. To model this variation, recent work has explored sociodemographic prompting, a technique, which steers the output of prompt-based models towards answers that humans with specific sociodemographic profiles would give. However, the available NLP literature disagrees on the efficacy of this technique — it remains unclear for which tasks and scenarios it can help, and the role of the individual factors in sociodemographic prompting is still unexplored. We address this research gap by presenting the largest and most comprehensive study of sociodemographic prompting today. We use it to analyze its influence on model sensitivity, performance and robustness across seven datasets and six instruction-tuned model families. We show that sociodemographic information affects model predictions and can be beneficial for improving zero-shot learning in subjective NLP tasks.However, its outcomes largely vary for different model types, sizes, and datasets, and are subject to large variance with regards to prompt formulations. Most importantly, our results show that sociodemographic prompting should be used with care when used for data annotation or studying LLM alignment.",26
2016,Counterspeech on twitter: A field study. Dangerous Speech Project,Susan Benesch,Other,NLP,"As hateful and extremist content proliferates online, ‘counterspeech’ is gaining currency as a
means of diminishing it.  No wonder: counterspeech doesn’t impinge on freedom of 1
expression and can be practiced by almost anyone, requiring neither law nor institutions. The
idea that ‘more speech’ is a remedy for harmful speech has been familiar in liberal
democratic thought at least since U.S. Supreme Court Justice Louis Brandeis declared it in
1927.  We are still without evidence, however, that counterspeech actually diminishes 2
harmful speech or its effects. This would be very hard to measure offline but is a bit easier
online, where speech and responses to it are recorded. In this paper we make a modest start.
Specifically we ask: in what forms and circumstances does counterspeech ­ which we define
as a direct response to hateful or dangerous speech ­ favorably influence discourse and
perhaps even behavior?
To our knowledge, this is the first study of Internet users (not a government or organization)
counterspeaking spontaneously on a public platform like Twitter. Our findings are qualitative
and anecdotal, since reliable quantitative detection of hateful speech or counterspeech is a
problem yet to be fully solved due to the wide variations in language employed, although we
made progress, as reported in an earlier paper that was part of this project (Saleem, Dillon,
Benesch, & Ruths, 2016).
We have identified four categories or “vectors” in each of which counterspeech functions
quite differently, as hateful speech also does: one­to­one exchanges, many­to­one,
one­to­many, and many­to­many. We also present a set of counterspeech strategies
extrapolated from our data, with examples of tweets that illustrate those strategies at work,
and suggestions for which ones may be successful.",16
2023,Detoxifying Online Discourse: A Guided Response Generation Approach for Reducing Toxicity in User-Generated Text,"Ritwik Bose, Ian Perera, Bonnie Dorr",Workshop on Social Influence in Conversations,NLP,"The expression of opinions, stances, and moral foundations on social media often coincide with toxic, divisive, or inflammatory language that can make constructive discourse across communities difficult. Natural language generation methods could provide a means to reframe or reword such expressions in a way that fosters more civil discourse, yet current Large Language Model (LLM) methods tend towards language that is too generic or formal to seem authentic for social media discussions. We present preliminary work on training LLMs to maintain authenticity while presenting a community’s ideas and values in a constructive, non-toxic manner.",4
2024,How large language models can reshape collective intelligence,"Jason W. Burton, Ezequiel Lopez-Lopez, Shahar Hechtlinger, Zoe Rahwan, Samuel Aeschbach, Michiel A. Bakker, Joshua A. Becker, Aleks Berditchevskaia, Julian Berger, Levin Brinkmann, Lucie Flek, Stefan M. Herzog, Saffron Huang, Sayash Kapoor, Arvind Narayanan, Anne-Marie Nussberger, Taha Yasseri, Pietro Nickl, Abdullah Almaatouq, Ulrike Hahn, Ralf H. J. M. Kurvers, Susan Leavy, Iyad Rahwan, Divya Siddarth, Alice Siu, Anita W. Woolley, Dirk U. Wulff & Ralph Hertwig ",Nature human behaviour,Computational Social Science,"Collective intelligence underpins the success of groups, organizations, markets and societies. Through distributed cognition and coordination, collectives can achieve outcomes that exceed the capabilities of individuals-even experts-resulting in improved accuracy and novel capabilities. Often, collective intelligence is supported by information technology, such as online prediction markets that elicit the 'wisdom of crowds', online forums that structure collective deliberation or digital platforms that crowdsource knowledge from the public. Large language models, however, are transforming how information is aggregated, accessed and transmitted online. Here we focus on the unique opportunities and challenges this transformation poses for collective intelligence. We bring together interdisciplinary perspectives from industry and academia to identify potential benefits, risks, policy-relevant considerations and open research questions, culminating in a call for a closer examination of how large language models affect humans' ability to collectively tackle complex problems.",14
2020,Is this Dialogue Coherent? Learning from Dialogue Acts and Entities,"Alessandra Cervone, Giuseppe Riccardi",Annual Meeting of the Special Interest Group on Discourse and Dialogue,NLP,"In this work, we investigate the human perception of coherence in open-domain dialogues. In particular, we address the problem of annotating and modeling the coherence of next-turn candidates while considering the entire history of the dialogue. First, we create the Switchboard Coherence (SWBD-Coh) corpus, a dataset of human-human spoken dialogues annotated with turn coherence ratings, where next-turn candidate utterances ratings are provided considering the full dialogue context. Our statistical analysis of the corpus indicates how turn coherence perception is affected by patterns of distribution of entities previously introduced and the Dialogue Acts used. Second, we experiment with different architectures to model entities, Dialogue Acts and their combination and evaluate their performance in predicting human coherence ratings on SWBD-Coh. We find that models combining both DA and entity information yield the best performances both for response selection and turn coherence rating.",19
2019,Trouble on the Horizon: Forecasting the Derailment of Online Conversations as they Develop,"Jonathan P. Chang, Cristian Danescu-Niculescu-Mizil",EMNLP,NLP,"Online discussions often derail into toxic exchanges between participants. Recent efforts mostly focused on detecting antisocial behavior after the fact, by analyzing single comments in isolation. To provide more timely notice to human moderators, a system needs to preemptively detect that a conversation is heading towards derailment before it actually turns toxic. This means modeling derailment as an emerging property of a conversation rather than as an isolated utterance-level event. Forecasting emerging conversational properties, however, poses several inherent modeling challenges. First, since conversations are dynamic, a forecasting model needs to capture the flow of the discussion, rather than properties of individual comments. Second, real conversations have an unknown horizon: they can end or derail at any time; thus a practical forecasting model needs to assess the risk in an online fashion, as the conversation develops. In this work we introduce a conversational forecasting model that learns an unsupervised representation of conversational dynamics and exploits it to predict future derailment as the conversation develops. By applying this model to two new diverse datasets of online conversations with labels for antisocial events, we show that it outperforms state-of-the-art systems at forecasting derailment.",58
2024,Exploring the Potential of Large Language Models in Computational Argumentation,"Guizhen Chen, Liying Cheng, Anh Tuan Luu, Lidong Bing",ACL,NLP,"Computational argumentation has become an essential tool in various domains, including law, public policy, and artificial intelligence. It is an emerging research field in natural language processing that attracts increasing attention. Research on computational argumentation mainly involves two types of tasks: argument mining and argument generation. As large language models (LLMs) have demonstrated impressive capabilities in understanding context and generating natural language, it is worthwhile to evaluate the performance of LLMs on diverse computational argumentation tasks. This work aims to embark on an assessment of LLMs, such as ChatGPT, Flan models, and LLaMA2 models, in both zero-shot and few-shot settings. We organize existing tasks into six main categories and standardize the format of fourteen openly available datasets. In addition, we present a new benchmark dataset on counter speech generation that aims to holistically evaluate the end-to-end performance of LLMs on argument mining and argument generation. Extensive experiments show that LLMs exhibit commendable performance across most of the datasets, demonstrating their capabilities in the field of argumentation. Our analysis offers valuable suggestions for evaluating computational argumentation and its integration with LLMs in future research endeavors.",22
2024,Self-playing Adversarial Language Game Enhances LLM Reasoning,"Pengyu Cheng, Tianhao Hu, Han Xu, Zhisong Zhang, Zheng Yuan, Yong Dai, Lei Han, Nan Du, Xiaolong Li",NeurIPS ,Computer Science,"We explore the potential of self-play training for large language models (LLMs) in a two-player adversarial language game called Adversarial Taboo. In this game, an attacker and a defender communicate around a target word only visible to the attacker. The attacker aims to induce the defender to speak the target word unconsciously, while the defender tries to infer the target word from the attacker's utterances. To win the game, both players must have sufficient knowledge about the target word and high-level reasoning ability to infer and express in this information-reserved conversation. Hence, we are curious about whether LLMs' reasoning ability can be further enhanced by Self-Playing this Adversarial language Game (SPAG). With this goal, we select several open-source LLMs and let each act as the attacker and play with a copy of itself as the defender on an extensive range of target words. Through reinforcement learning on the game outcomes, we observe that the LLMs' performances uniformly improve on a broad range of reasoning benchmarks. Furthermore, iteratively adopting this self-play process can continuously promote LLMs' reasoning abilities",13
2024,Can Language Model Moderators Improve the Health of Online Discourse?,"Hyundong Cho, Shuai Liu, Taiwei Shi, Darpan Jain, Basem Rizk, Yuyang Huang, Zixun Lu, Nuan Wen, Jonathan Gratch, Emilio Ferrara, Jonathan May",NAACL,NLP,"Conversational moderation of online communities is crucial to maintaining civility for a constructive environment, but it is challenging to scale and harmful to moderators. The inclusion of sophisticated natural language generation modules as a force multiplier to aid human moderators is a tantalizing prospect, but adequate evaluation approaches have so far been elusive. In this paper, we establish a systematic definition of conversational moderation effectiveness grounded on moderation literature and establish design criteria for conducting realistic yet safe evaluation. We then propose a comprehensive evaluation framework to assess models’ moderation capabilities independently of human intervention. With our framework, we conduct the first known study of language models as conversational moderators, finding that appropriately prompted models that incorporate insights from social science can provide specific and fair feedback on toxic behavior but struggle to influence users to increase their levels of respect and cooperation.",8
2024,Coherence-based Dialogue Discourse Structure Extraction using Open-Source Large Language Models,"Gaetano Cimino, Chuyuan Li, Giuseppe Carenini, Vincenzo Deufemia",Annual Meeting of the Special Interest Group on Discourse and Dialogue,NLP,"Despite the challenges posed by data sparsity in discourse parsing for dialogues, unsupervised methods have been underexplored. Leveraging recent advances in Large Language Models (LLMs), in this paper we investigate an unsupervised coherence-based method to build discourse structures for multi-party dialogues using open-source LLMs fine-tuned on conversational data. Specifically, we propose two algorithms that extract dialogue structures by identifying their most coherent sub-dialogues: DS-DP employs a dynamic programming strategy, while DS-FLOW applies a greedy approach. Evaluation on the STAC corpus demonstrates a micro-F1 score of 58.1%, surpassing prior unsupervised methods. Furthermore, on a cleaned subset of the Molweni corpus, the proposed method achieves a micro-F1 score of 74.7%, highlighting its effectiveness across different corpora.",?
2024,"An Interactional Account of Empathy
in Human-Machine Communication","Rafael Pereira, Carla Mendes, Nuno Costa, Luis Frazão, Antonio Fernández-Caballero, António Pereira",Human-Machine Communication,Computer Science,"Efforts to develop empathetic agents, or systems capable of responding appropriately to
emotional content, have increased as the deployment of such systems in socially complex
scenarios becomes more commonplace. In the context of human-machine communication
(HMC), the ability to create the perception of empathy is achieved in large part through
linguistic behavior. However, studies of how language is used to display and respond to
emotion in ways deemed empathetic are limited. This article aims to address this gap,
demonstrating how an interactional linguistics informed methodological approach
can be applied to the study of empathy in HMC. We present an analysis of empathetic
response strategies in HMC and examine how these diverge from the practices employed
in human-human dialogue. The specific challenges encountered by current systems are
reviewed and their implications for future work on HMC considered.",6
2022,Personalized Interventions for Online Moderation,"Stefano Cresci, Amaury Trujillo, Tiziano Fagni","ACM Conference on Hypertext and Social Media
",Computer Science,"Current online moderation follows a one-size-fits-all approach, where each intervention is applied in the same way to all users. This naïve approach is challenged by established socio-behavioral theories and by recent empirical results that showed the limited effectiveness of such interventions. We propose a paradigm-shift in online moderation by moving towards a personalized and user-centered approach. Our multidisciplinary vision combines state-of-the-art theories and practices in diverse fields such as computer science, sociology and psychology, to design personalized moderation interventions (PMIs). In outlining the path leading to the next-generation of moderation interventions, we also discuss the most prominent challenges introduced by such a disruptive change.",17
2012,Echoes of power: language effects and power differences in social interaction,"Cristian Danescu-Niculescu-Mizil, Lillian Lee, Bo Pang, Jon Kleinberg",international conference on World Wide Web,Computer Science,"Understanding social interaction within groups is key to analyzing online communities. Most current work focuses on structural properties: who talks to whom, and how such interactions form larger network structures. The interactions themselves, however, generally take place in the form of natural language --- either spoken or written --- and one could reasonably suppose that signals manifested in language might also provide information about roles, status, and other aspects of the group's dynamics. To date, however, finding domain-independent language-based signals has been a challenge.
Here, we show that in group discussions, power differentials between participants are subtly revealed by how much one individual immediately echoes the linguistic style of the person they are responding to. Starting from this observation, we propose an analysis framework based on linguistic coordination that can be used to shed light on power relationships and that works consistently across multiple types of power --- including a more ""static"" form of power based on status differences, and a more ""situational"" form of power in which one individual experiences a type of dependence on another. Using this framework, we study how conversational behavior can reveal power relationships in two very different settings: discussions among Wikipedians and arguments before the U. S. Supreme Court.",464
2013,A computational approach to politeness with application to social factors,"Cristian Danescu-Niculescu-Mizil, Moritz Sudhof, Dan Jurafsky, Jure Leskovec, Christopher Potts",ACL,NLP,"We propose a computational framework
for identifying linguistic aspects of politeness. Our starting point is a new corpus
of requests annotated for politeness, which
we use to evaluate aspects of politeness
theory and to uncover new interactions
between politeness markers and context.
These findings guide our construction of
a classifier with domain-independent lexical and syntactic features operationalizing
key components of politeness theory, such
as indirection, deference, impersonalization and modality. Our classifier achieves
close to human performance and is effective across domains. We use our framework to study the relationship between politeness and social power, showing that polite Wikipedia editors are more likely to
achieve high status through elections, but,
once elevated, they become less polite. We
see a similar negative correlation between
politeness and power on Stack Exchange,
where users at the top of the reputation
scale are less polite than those at the bottom. Finally, we apply our classifier to
a preliminary analysis of politeness variation by gender and community.",579
2022,How to disagree well: Investigating the dispute tactics used on Wikipedia,"Christine De Kock, Tom Stafford, Andreas Vlachos",EMNLP,NLP,"Disagreements are frequently studied from the perspective of either detecting toxicity or analysing argument structure. We propose a framework of dispute tactics which unifies these two perspectives, as well as other dialogue acts which play a role in resolving disputes, such as asking questions and providing clarification. This framework includes a preferential ordering among rebuttal-type tactics, ranging from ad hominem attacks to refuting the central argument. Using this framework, we annotate 213 disagreements (3,865 utterances) from Wikipedia Talk pages. This allows us to investigate research questions around the tactics used in disagreements; for instance, we provide empirical validation of the approach to disagreement recommended by Wikipedia. We develop models for multilabel prediction of dispute tactics in an utterance, achieving the best performance with a transformer-based label powerset model. Adding an auxiliary task to incorporate the ordering of rebuttal tactics further yields a statistically significant increase. Finally, we show that these annotations can be used to provide useful additional signals to improve performance on the task of predicting escalation.",7
2021,I Beg to Differ: A study of constructive disagreement in online conversations,"Christine De Kock, Andreas Vlachos",EACL,NLP,"Disagreements are pervasive in human communication. In this paper we investigate what makes disagreement constructive. To this end, we construct WikiDisputes, a corpus of 7425 Wikipedia Talk page conversations that contain content disputes, and define the task of predicting whether disagreements will be escalated to mediation by a moderator. We evaluate feature-based models with linguistic markers from previous work, and demonstrate that their performance is improved by using features that capture changes in linguistic markers throughout the conversations, as opposed to averaged values. We develop a variety of neural models and show that taking into account the structure of the conversation improves predictive accuracy, exceeding that of feature-based models. We assess our best neural model in terms of both predictive accuracy and uncertainty by evaluating its behaviour when it is only exposed to the beginning of the conversation, finding that model accuracy improves and uncertainty reduces as models are exposed to more information.",23
2015,Which public and why deliberate?--A scoping review of public deliberation in public health and health policy research,"Chris Degeling, Stacy M Carter, Lucie Rychetnik ",Social science & medicine,Social Science,"Deliberative methods are of increasing interest to public health researchers and policymakers. We systematically searched the peer-reviewed literature to identify public health and health policy research involving deliberative methods and report how deliberative methods have been used. We applied a taxonomy developed with reference to health policy and science and technology studies literatures to distinguish how deliberative methods engage different publics: citizens (ordinary people who are unfamiliar with the issues), consumers (those with relevant personal experience e.g. of illness) and advocates (those with technical expertise or partisan interests). We searched four databases for empirical studies in English published 1996-2013. This identified 78 articles reporting on 62 distinct events from the UK, USA, Canada, Australasia, Europe, Israel, Asia and Africa. Ten different types of deliberative techniques were used to represent and capture the interests and preferences of different types of public. Citizens were typically directed to consider community interests and were treated as a resource to increase democratic legitimacy. Citizens were preferred in methodological studies (those focused on understanding the techniques). Consumers were directed to focus on personal preferences; thus convened not as a source of policy decisions, but of knowledge about what those affected by the issue would accept. Advocates-who are most commonly used as expert witnesses in juries-were sometimes engaged to deliberate with consumers or citizens. This almost always occurred in projects directly linked to policy processes. This suggests health policymakers may value deliberative methods as a way of understanding disagreement between perspectives. Overall however, the 'type' of public sought was often not explicit, and their role not specified. This review provides new insight into the heterogeneity and rising popularity of deliberative methods, and indicates a need for greater clarity regarding both the constitution of publics and the relative usefulness of different deliberative techniques.",240
2017,Interactive Visual Analysis of Transcribed Multi-Party Discourse,"Mennatallah El-Assady, Annette Hautli-Janisz, Valentin Gold, Miriam Butt, Katharina Holzinger, Daniel Keim",ACL,NLP,"We present the first web-based Visual
Analytics framework for the analysis of
multi-party discourse data using verbatim
text transcripts. Our framework supports
a broad range of server-based processing
steps, ranging from data mining and statistical analysis to deep linguistic parsing
of English and German. On the client-side,
browser-based Visual Analytics components enable multiple perspectives on the
analyzed data. These interactive visualizations allow exploratory content analysis,
argumentation pattern review and speaker
interaction modeling.",31
2016,ConToVi: Multi‐Party Conversation Exploration using Topic‐Space Views,"Mennatallah El-Assady, Valentin Gold, Carmela Acevedo, Christopher Collins, Daniel Keim",Computer Graphics Forum,Computer Science,"We introduce a novel visual analytics approach to analyze speaker behavior patterns in multi-party conversations. We propose
Topic-Space Views to track the movement of speakers across the thematic landscape of a conversation. Our tool is designed to
assist political science scholars in exploring the dynamics of a conversation over time to generate and prove hypotheses about
speaker interactions and behavior patterns. Moreover, we introduce a glyph-based representation for each speaker turn based
on linguistic and statistical cues to abstract relevant text features. We present animated views for exploring the general behavior
and interactions of speakers over time and interactive steady visualizations for the detailed analysis of a selection of speakers.
Using a visual sedimentation metaphor we enable the analysts to track subtle changes in the flow of a conversation over time
while keeping an overview of all past speaker turns. We evaluate our approach on real-world datasets and the results have been
insightful to our domain experts.",95
2023,Bridging Argument Quality and Deliberative Quality Annotations with Adapters,"Neele Falk, Gabriella Lapesa",EACL,NLP,"Assessing the quality of an argument is a complex, highly subjective task, influenced by heterogeneous factors (e.g., prior beliefs of the annotators, topic, domain, and application), and crucial for its impact in downstream tasks (e.g., argument retrieval or generation). Both the Argument Mining and the Social Science community have devoted plenty of attention to it, resulting in a wide variety of argument quality dimensions and a large number of annotated resources. This work aims at a better understanding of how the different aspects of argument quality relate to each other from a practical point of view. We employ adapter-fusion (Pfeiffer et al., 2021) as a multi-task learning framework which a) can improve the prediction of individual quality dimensions by injecting knowledge about related dimensions b) is efficient and modular and c) can serve as an analysis tool to investigate relations between different dimensions. We conduct experiments on 6 datasets and 20 quality dimensions. We find that the majority of the dimensions can be learned as a weighted combination of other quality aspects, and that for 8 dimensions adapter fusion improves quality prediction. Last, we show the benefits of this approach by improving the performance in an extrinsic, out-of-domain task: prediction of moderator interventions in a deliberative forum.",13
2021,Predicting Moderation of Deliberative Arguments: Is Argument Quality the Key?,"Neele Falk, Iman Jundi, Eva Maria Vecchi, Gabriella Lapesa",Workshop on Argument Mining,NLP,"Human moderation is commonly employed in deliberative contexts (argumentation and discussion targeting a shared decision on an issue relevant to a group, e.g., citizens arguing on how to employ a shared budget). As the scale of discussion enlarges in online settings, the overall discussion quality risks to drop and moderation becomes more important to assist participants in having a cooperative and productive interaction. The scale also makes it more important to employ NLP methods for(semi-)automatic moderation, e.g. to prioritize when moderation is most needed. In this work, we make the first steps towards (semi-)automatic moderation by using state-of-the-art classification models to predict which posts require moderation, showing that while the task is undoubtedly difficult, performance is significantly above baseline. We further investigate whether argument quality is a key indicator of the need for moderation, showing that surprisingly, high quality arguments also trigger moderation. We make our code and data publicly available.",11
2024,Moderation in the Wild: Investigating User-Driven Moderation in Online Discussions,"Neele Falk, Eva Vecchi, Iman Jundi, Gabriella Lapesa",EACL,NLP,"Effective content moderation is imperative for fostering healthy and productive discussions in online domains. Despite the substantial efforts of moderators, the overwhelming nature of discussion flow can limit their effectiveness. However, it is not only trained moderators who intervene in online discussions to improve their quality. “Ordinary” users also act as moderators, actively intervening to correct information of other users’ posts, enhance arguments, and steer discussions back on course.This paper introduces the phenomenon of user moderation, documenting and releasing UMOD, the first dataset of comments in whichusers act as moderators. UMOD contains 1000 comment-reply pairs from the subreddit r/changemyview with crowdsourced annotations from a large annotator pool and with a fine-grained annotation schema targeting the functions of moderation, stylistic properties(aggressiveness, subjectivity, sentiment), constructiveness, as well as the individual perspectives of the annotators on the task. The releaseof UMOD is complemented by two analyses which focus on the constitutive features of constructiveness in user moderation and on thesources of annotator disagreements, given the high subjectivity of the task.",3
2022,A Survey on Dialogue Summarization: Recent Advances and New Frontiers,"Xiachong Feng, Xiaocheng Feng, Bing Qin",IJCAI,Computer Science,"Dialogue summarization aims to condense the original dialogue into a shorter version covering salient
information, which is a crucial way to reduce dialogue data overload. Recently, the promising
achievements in both dialogue systems and natural language generation techniques drastically lead
this task to a new landscape, which results in signifcant research attentions. However, there still
remains a lack of a comprehensive survey for this
task. To this end, we take the frst step and present
a thorough review of this research feld carefully
and widely. In detail, we systematically organize
the current works according to the characteristics of
each domain, covering meeting, chat, email thread,
customer service and medical dialogue. Additionally, we provide an overview of publicly available
research datasets as well as organize two leaderboards under unifed metrics. Furthermore, we discuss some future directions, including faithfulness,
multi-modal, multi-domain and multi-lingual dialogue summarization, and give our thoughts respectively. We hope that this frst survey of dialogue
summarization can provide the community with a
quick access and a general picture to this task and
motivate future researches.",105
2012,Behind the Article: Recognizing Dialog Acts in Wikipedia Talk Pages,"Oliver Ferschke, Iryna Gurevych, Yevgen Chebotar",EACL,NLP,"In this paper, we propose an annotation schema for the discourse analysis of
Wikipedia Talk pages aimed at the coordination efforts for article improvement.
We apply the annotation schema to a corpus of 100 Talk pages from the Simple
English Wikipedia and make the resulting
dataset freely available for download1
. Furthermore, we perform automatic dialog act
classification on Wikipedia discussions and
achieve an average F1-score of 0.82 with
our classification pipeline.",102
2018,Deliberative Democracy with the Online Deliberation Platform,"James Fishkin, Nikhil Garg, Lodewijk Gelauff, Ashish Goel, Kamesh Munagala, Sukolsak
Sakshuwong, Alice Siu, Sravya Yandamuri",AAAI,Computer Science,"We introduce the Stanford Online Deliberation Platform, a web-based platform that facilitates constructive discussions on civic issues with the use of an automated moderator. The automated moderator performs this function by stimulating participants to consider arguments from both sides of all proposals, maintaining civility in the discussion, encouraging equitable participation by all participants, and providing a structured collaboration phase for participants to come up with a small set of questions or action items. We will demo the functionality of this platform in the context of its primary intended application, that of online Deliberative Polling.",3
2018,Letting the faculty deliberate: analyzing online deliberation in academia using a comprehensive approach, DM Friess,"Journal of Information Tech
nology & Politics",Social Science,"While the scholarship on online deliberation has recently witnessed remarkable growth, most studies have focused on different parts of deliberation, thus neglecting other parts of the theorized process. This paper presents a case study of online deliberation in academia using a framework including three analytical parts: a design fostering deliberation (institutional inputs), the quality of the communication process (communicative throughput), and the expected benefits of deliberation (productive outcomes). Each level addressed in the framework is both rooted in deliberative theory and complemented by empirical findings. Applying the framework to a case study on online deliberation about new PhD guidelines in a German science faculty demonstrates that the framework is viable for empirical research. In analyzing 435 comments and an online survey completed by 230 participants, the case study reveals that if deliberative standards at the institutional input level are met there is considerable deliberative quality at the level of communicative throughput, and expected outcomes could thus emerge. This example makes a case for further online deliberation initiatives in similar contexts such as parties or organizations that must decide on important issues or legally binding norms.",5
2023,Achieving parity with human moderators,"Lodewijk Gelauff, Liubov Nikolenko, Sukolsak Sakshuwong, James Fishkin, Ashish Goel, Kamesh Munagala, Alice Siu","
The Routledge Handbook of Collective Intelligence for Democracy and Governance",Social Science,"We describe the design of a video-conferencing platform for online deliberation that is self-moderating in the sense that it works without a human moderator. The platform includes an audio and video conferencing system and incorporates automated and user-assisted moderation, queues, nudges, speaker management, and agenda management. It can be configured to mirror the moderation practices of the Deliberative Polling framework (Fishkin, Luskin, and Jowell 2000), and has also been used in other deliberative settings. We evaluate the efficacy of our platform by analyzing surveys and metrics from a Japanese Deliberative Polling exercise conducted on this platform. We find that the online platform performs on par with an earlier in-person moderated deliberation on a very similar topic, overcoming both the need to convene in-person and the need to recruit and train effective human moderators. We present preliminary evidence that our platform leads to increased gender equity in participation compared to in-person deliberation, and also performs well on equitable participation across two other demographic factors commonly associated with privilege: income and education. Finally, we share some practical takeaways on how to effectively run a deliberative exercise through online video chat on a platform like ours.",8
2018,"Deliberative Abilities and Influence in a
Transnational Deliberative Poll (EuroPolis)
","Marlène Gerber, André Bächtiger, Susumu Shikano, Simon Reber, Samuel Rohr ",British Journal of Political Science,Social Science,"This article investigates the deliberative abilities of ordinary citizens in the context of ‘EuroPolis’, a
transnational deliberative poll. Drawing upon a philosophically grounded instrument, an updated version
of the Discourse Quality Index (DQI), it explores how capable European citizens are of meeting deliberative ideals; whether socio-economic, cultural and psychological biases affect the ability to deliberate;
and whether opinion change results from the exchange of arguments. On the positive side, EuroPolis
shows that the ideal deliberator scoring high on all deliberative standards does actually exist, and that
participants change their opinions more often when rational justification is used in the discussions. On
the negative side, deliberative abilities are unequally distributed: in particular, working-class members are
less likely to contribute to a high standard of deliberation.",127
2022,DEAM: Dialogue Coherence Evaluation using AMR-based Semantic Manipulations,"Sarik Ghazarian, Nuan Wen, Aram Galstyan, Nanyun Peng",ACL,NLP,"Automatic evaluation metrics are essential for the rapid development of open-domain dialogue systems as they facilitate hyper-parameter tuning and comparison between models. Although recently proposed trainable conversation-level metrics have shown encouraging results, the quality of the metrics is strongly dependent on the quality of training data. Prior works mainly resort to heuristic text-level manipulations (e.g. utterances shuffling) to bootstrap incoherent conversations (negative examples) from coherent dialogues (positive examples). Such approaches are insufficient to appropriately reflect the incoherence that occurs in interactions between advanced dialogue models and humans. To tackle this problem, we propose DEAM, a Dialogue coherence Evaluation metric that relies on Abstract Meaning Representation (AMR) to apply semantic-level Manipulations for incoherent (negative) data generation. AMRs naturally facilitate the injection of various types of incoherence sources, such as coreference inconsistency, irrelevancy, contradictions, and decrease engagement, at the semantic level, thus resulting in more natural incoherent samples. Our experiments show that DEAM achieves higher correlations with human judgments compared to baseline methods on several dialog datasets by significant margins. We also show that DEAM can distinguish between coherent and incoherent dialogues generated by baseline manipulations, whereas those baseline models cannot detect incoherent examples generated by DEAM. Our results demonstrate the potential of AMR-based semantic manipulations for natural negative example generation.",39
2024,What is “Dialogue” in Public Engagement with Science and Technology? Bridging STS and Deliberative Democracy,,Minerva ,Social Science,"This article provides a narrative review on the concept of dialogue within STS and Deliberative Democracy academic literature. Through this review I find that dialogue has been used in unsystematic, conflicting and sometimes even misleading ways that conflate dialogue and deliberation. Dialogue is used flexibly as an epistemological standpoint, an interactional format, a tradition and format of public engagement, an interactional phenomenon and an idealised moment. I provide a characterisation and theorisation of dialogue that seeks to integrate critical and historical accounts of dialogue, while introducing analytical dimensions that can be leveraged for further research. By bridging STS and Deliberative Democracy, I advance a definition of dialogue as a public technology.",?
2012,Metrics and Evaluation of Spoken Dialogue Systems,Helen Hastie, Data-Driven Methods for Adaptive Spoken Dialogue Systems ,Computer Science,"The ultimate goal of an evaluation framework is to determine a dialogue system’s performance, which can be defined as “the ability of a system to provide the function it has been designed for” [32]. Also important, particularly for industrial systems, is dialogue quality or usability. To measure usability, one can use subjective measures such as User Satisfaction or likelihood of future use. These subjective metrics are difficult to measure and are dependent on the context and the individual user, whose goal and values may differ from other users. This chapter will survey evaluation frameworks and discuss their advantages and disadvantages. We will examine metrics for evaluating system performance and dialogue quality. We will also discuss evaluation techniques that can be used to automatically detect problems in the dialogue, thus filtering out good dialogues and leaving poor dialogues for further evaluation and investigation [62].",36
2017,Analyzing the Semantic Types of Claims and Premises in an Online Persuasive Forum,"Christopher Hidey, Elena Musi, Alyssa Hwang, Smaranda Muresan, Kathy McKeown",Workshop on Argument Mining,NLP,"Argumentative text has been analyzed both theoretically and computationally in terms of argumentative structure that consists of argument components (e.g., claims, premises) and their argumentative relations (e.g., support, attack). Less emphasis has been placed on analyzing the semantic types of argument components. We propose a two-tiered annotation scheme to label claims and premises and their semantic types in an online persuasive forum, Change My View, with the long-term goal of understanding what makes a message persuasive. Premises are annotated with the three types of persuasive modes: ethos, logos, pathos, while claims are labeled as interpretation, evaluation, agreement, or disagreement, the latter two designed to account for the dialogical nature of our corpus. We aim to answer three questions: 1) can humans reliably annotate the semantic types of argument components? 2) are types of premises/claims positioned in recurrent orders? and 3) are certain types of claims and/or premises more likely to appear in persuasive messages than in non-persuasive messages?",141
2016,"MultiConVis: A Visual Text Analytics System for Exploring a
Collection of Online Conversations","Enamul Hoque, Giuseppe Carenini","International Conference on Intelligent User Interfaces",Computer Science,"Online conversations, such as blogs, provide rich amount of information and opinions about popular queries. Given a query, traditional blog sites return a set of conversations often consisting of thousands of comments with complex thread structure. Since the interfaces of these blog sites do not provide any overview of the data, it becomes very difficult for the user to explore and analyze such a large amount of conversational data. In this paper, we present MultiConVis, a visual text analytics system designed to support the exploration of a collection of online conversations. Our system tightly integrates NLP techniques for topic modeling and sentiment analysis with information visualizations, by considering the unique characteristics of online conversations. The resulting interface supports the user exploration, starting from a possibly large set of conversations, then narrowing down to the subset of conversations, and eventually drilling-down to the set of comments of one conversation. Our evaluations through case studies with domain experts and a formal user study with regular blog readers illustrate the potential benefits of our approach, when compared to a traditional blog reading interface.",53
2023,A fine-grained comparison of pragmatic language understanding in humans and language models,"Jennifer Hu, Sammy Floyd, Olessia Jouravlev, Evelina Fedorenko, Edward Gibson",ACL,NLP,"Pragmatics and non-literal language understanding are essential to human communication, and present a long-standing challenge for artificial language models. We perform a fine-grained comparison of language models and humans on seven pragmatic phenomena, using zero-shot prompting on an expert-curated set of English materials. We ask whether models (1) select pragmatic interpretations of speaker utterances, (2) make similar error patterns as humans, and (3) use similar linguistic cues as humans to solve the tasks. We find that the largest models achieve high accuracy and match human error patterns: within incorrect responses, models favor literal interpretations over heuristic-based distractors. We also find preliminary evidence that models and humans are sensitive to similar linguistic cues. Our results suggest that pragmatic behaviors can emerge in models without explicitly constructed representations of mental states. However, models tend to struggle with phenomena relying on social expectation violations.",5
2018,WikiConv: A Corpus of the Complete Conversational History of a Large Online Collaborative Community,"Yiqing Hua, Cristian Danescu-Niculescu-Mizil, Dario Taraborelli, Nithum Thain, Jeffery Sorensen, Lucas Dixon",EMNLP,NLP,"We present a corpus that encompasses the complete history of conversations between contributors to Wikipedia, one of the largest online collaborative communities. By recording the intermediate states of conversations - including not only comments and replies, but also their modifications, deletions and restorations - this data offers an unprecedented view of online conversation. Our framework is designed to be language agnostic, and we show that it extracts high quality data in both Chinese and English. This level of detail supports new research questions pertaining to the process (and challenges) of large-scale online collaboration. We illustrate the corpus’ potential with two case studies on English Wikipedia that highlight new perspectives on earlier work. First, we explore how a person’s conversational behavior depends on how they relate to the discussion’s venue. Second, we show that community moderation of toxic behavior happens at a higher rate than previously estimated.",39
2020,GRADE: Automatic Graph-Enhanced Coherence Metric for Evaluating Open-Domain Dialogue Systems,"Lishan Huang, Zheng Ye, Jinghui Qin, Liang Lin, Xiaodan Liang",EMNLP,NLP,"Automatically evaluating dialogue coherence is a challenging but high-demand ability for developing high-quality open-domain dialogue systems. However, current evaluation metrics consider only surface features or utterance-level semantics, without explicitly considering the fine-grained topic transition dynamics of dialogue flows. Here, we first consider that the graph structure constituted with topics in a dialogue can accurately depict the underlying communication logic, which is a more natural way to produce persuasive metrics. Capitalized on the topic-level dialogue graph, we propose a new evaluation metric GRADE, which stands for Graph-enhanced Representations for Automatic Dialogue Evaluation. Specifically, GRADE incorporates both coarse-grained utterance-level contextualized representations and fine-grained topic-level graph representations to evaluate dialogue coherence. The graph representations are obtained by reasoning over topic-level dialogue graphs enhanced with the evidence from a commonsense graph, including k-hop neighboring representations and hop-attention weights. Experimental results show that our GRADE significantly outperforms other state-of-the-art metrics on measuring diverse dialogue models in terms of the Pearson and Spearman correlations with human judgments. Besides, we release a new large-scale human evaluation benchmark to facilitate future research on automatic metrics.",105
2024,ArguSense: Argument-Centric Analysis of Online Discourse,"Arman Irani, Michalis Faloutsos, Kevin Esterling",AAAI,NLP,"How  can  we  model  arguments  and  their  dynamics  in  on-line forum discussions? The meteoric rise of online forumspresents researchers across different disciplines with an un-precedented  opportunity:  we  have  access  to  texts  contain-ing  discourse  between  groups  of  users  generated  in  a  vol-untary and organic fashion. Most prior work so far has fo-cused on classifying individualmonologicalcomments as ei-ther  argumentative  or  not  argumentative.  However,  few  ef-forts quantify and describe thedialogical processesbetweenusers found in online forum discourse: the structure and con-tent of interpersonal argumentation. Modeling dialogical dis-course requires the ability to identify the presence of argu-ments, group them into clusters, and summarize the contentand nature of clusters of arguments within a discussion threadin the forum. In this work, we develop ArguSense, a com-prehensive and systematic framework for understanding ar-guments and debate in online forums. Our framework con-sists of methods for, among other things: (a) detecting argu-ment  topics  in  an  unsupervised  manner;  (b)  describing  thestructure  of  arguments  within  threads  with  powerful  visu-alizations;  and  (c)  quantifying  the  content  and  diversity  ofthreads using argument similarity and clustering algorithms.We showcase our approach by analyzing the discussions offour communities on the Reddit platform over a span of 21months. Specifically, we analyze the structure and content ofthreads related to GMOs in forums related to agriculture orfarming to demonstrate the value of our framework",1
2024,Let’s discuss! Quality Dimensions and Annotated Datasets for Computational Argument Quality Assessment,"Rositsa V Ivanova, Thomas Huber, Christina Niklaus",EMNLP,NLP,"Research in the computational assessment of Argumentation Quality has gained popularity over the last ten years. Various quality dimensions have been explored through the creation of domain-specific datasets and assessment methods. We survey the related literature (211 publications and 32 datasets), while addressing potential overlaps and blurry boundaries to related domains. This paper provides a representative overview of the state of the art in Computational Argument Quality Assessment with a focus on quality dimensions and annotated datasets. The aim of the survey is to identify research gaps and to aid future discussions and work in the domain.",?
2024,A Comprehensive Survey on Process-Oriented Automatic Text Summarization with Exploration of LLM-Based Methods,"Hanlei Jin, Yang Zhang, Dan Meng, Jun Wang, Jinghua Tan",Arxiv,Computer Science,"Automatic Text Summarization (ATS), utilizing Natural Language Processing (NLP) algorithms, aims to create concise and accurate summaries, thereby significantly reducing the human effort required in processing large volumes of text. ATS has drawn considerable interest in both academic and industrial circles. Many studies have been conducted in the past to survey ATS methods; however, they generally lack practicality for real-world implementations, as they often categorize previous methods from a theoretical standpoint. Moreover, the advent of Large Language Models (LLMs) has altered conventional ATS methods. In this survey, we aim to 1) provide a comprehensive overview of ATS from a ``Process-Oriented Schema'' perspective, which is best aligned with real-world implementations; 2) comprehensively review the latest LLM-based ATS works; and 3) deliver an up-to-date survey of ATS, bridging the two-year gap in the literature. To the best of our knowledge, this is the first survey to specifically investigate LLM-based ATS methods.",87
2017,Evaluating Dialogs based on Grice’s Maxims,Prathyusha Jwalapuram,RANLP,NLP,"There is no agreed upon standard for the evaluation of conversational dialog systems, which are well-known to be hard to evaluate due to the difficulty in pinning down metrics that will correspond to human judgements and the subjective nature of human judgment itself. We explored the possibility of using Grice’s Maxims to evaluate effective communication in conversation. We collected some system generated dialogs from popular conversational chatbots across the spectrum and conducted a survey to see how the human judgements based on Gricean maxims correlate, and if such human judgments can be used as an effective evaluation metric for conversational dialog.",15
2024,Implanting LLM’s Knowledge via Reading Comprehension Tree for Toxicity Detection,"Hankun Kang, Tieyun Qian",ACL,NLP,"Toxicity detection plays a crucial role in maintaining the peace of the society. Existing methods can be roughly categorized as small language model (SLM) based and large language model (LLM) based. However, due to the limitation of SLMs on general knowledge and the potential embedded bias in LLMs despite their large amount of knowledge, it is not a good idea to detect toxicity only with either SLM or LLM based method.In this work, we propose to implant LLM’s knowledge into SLM based methods such that we can stick to both types of models’ strengths. To this end, we develop a reading comprehension (RC) tree to transfer knowledge between two models. Specifically, we first construct the RC tree, from an extensive to intensive reading perspective, to capture the local and global information in the text. We then model samples encoded by SLM and knowledge extracted from LLM as two distributions using the constructed RT tree. We finally transfer knowledge via optimal transportation between two distributions. Extensive experiments prove the effectiveness of our method on real-world and machine-generated datasets.",?
2021,DeliData: A dataset for deliberation in multi-party problem solving,"Georgi Karadzhov, Tom Stafford, Andreas Vlachos",ACM on Human-Computer Interaction,Computer Science,"Group deliberation enables people to collaborate and solve problems, however, it is understudied due to a lack of resources. To this end, we introduce the first publicly available dataset containing collaborative conversations on solving a well-established cognitive task, consisting of 500 group dialogues and 14k utterances. In 64% of these conversations, the group members are able to find a better solution than they had identified individually, and in 43.8% of the groups who had a correct answer as their final solution, none of the participants had solved the task correctly by themselves. Furthermore, we propose a novel annotation schema that captures deliberation cues and release all 14k utterances annotated with it. Finally, we use the proposed dataset to develop and evaluate two methods for generating deliberation utterances. The data collection platform, dataset and annotated corpus are publicly available at this https URL.",8
2022,Online deliberative matrix,Raphaël Kies,Research Methods in Deliberative Democracy,Social Science,"In the last decades, online deliberation has gained prominence amongst scholars in political science, political philosophy, political communication, and big data analysis. This chapter presents a method to assess online deliberation: the Online Deliberative Matrix (ODM). This matrix refers to a criteria that assesses the quality of deliberation taking place in online discursive spaces. The chapter provides the theoretical foundation of the matrix by referring to the ideal speech situation and the two-track model of democracy advocated by Jürgen Habermas. It then presents a detailed operationalization of this theory based on nine deliberative criteria and discusses some examples that fully, or partially draw on the ODM to evaluate the deliberativeness of online debates in different contexts.",?
2021,Moderator Chatbot for Deliberative Discussion: Effects of Discussion Structure and Discussant Facilitation,"Soomin Kim, Jinsu Eun, Joseph Seering, Joonhwan Lee",ACM on Human-Computer Interaction,Computer Science,"Online chat functions as a discussion channel for diverse social issues. However, deliberative discussion and consensus-reaching can be difficult in online chats in part because of the lack of structure. To explore the feasibility of a conversational agent that enables deliberative discussion, we designed and developed DebateBot, a chatbot that structures discussion and encourages reticent participants to contribute. We conducted a 2 (discussion structure: unstructured vs. structured) × 2 (discussant facilitation: unfacilitated vs. facilitated) between-subjects experiment (N = 64, 12 groups). Our findings are as follows: (1) Structured discussion positively affects discussion quality by generating diverse opinions within a group and resulting in a high level of perceived deliberative quality. (2) Facilitation drives a high level of opinion alignment between group consensus and independent individual opinions, resulting in authentic consensus reaching. Facilitation also drives more even contribution and a higher level of task cohesion and communication fairness. Our results suggest that a chatbot agent could partially substitute for a human moderator in deliberative discussions.",81
2024,Watch Your Language: Investigating Content Moderation with Large LanguageModels,"Deepak Kumar, Yousef Anees AbuHashem, Zakir Durumeric",AAAI,Computer Science,"Large language models (LLMs) have exploded in popularitydue to their ability to perform a wide array of natural languagetasks. Text-based  content  moderation is one  LLM use casethat has received recent enthusiasm, however, there is littleresearch investigating how LLMs can help in content moder-ation settings. In this work, we evaluate a suite of commodityLLMs on two common content moderation tasks: rule-basedcommunity moderation and toxic content detection. For rule-based community moderation, we instantiate 95 subcommu-nity  specific  LLMs  by  prompting  GPT-3.5  with  rules  from95 Reddit subcommunities. We find that GPT-3.5 is effectiveat  rule-based  moderation  for  many  communities,  achievinga median accuracy of 64% and a median precision of 83%.For toxicity detection, we evaluate a range of LLMs (GPT-3, GPT-3.5, GPT-4, Gemini Pro, LLAMA 2) and show thatLLMs significantly outperform currently widespread toxicityclassifiers. However, we also found that increases in modelsize add only marginal benefit to toxicity detection, suggest-ing a potential performance plateau for LLMs on toxicity de-tection  tasks.  We  conclude  by  outlining  avenues  for  futurework in studying LLMs and content moderation",31
2021,Heuristic Evaluation of Conversational Agents,"Raina Langevin, Ross J Lordon, Thi Avrahami, Benjamin R. Cowan, Tad Hirsch, Gary Hsieh","Conference on Human Factors in Computing Systems",Computer Science,"Conversational interfaces have risen in popularity as businesses and users adopt a range of conversational agents, including chatbots and voice assistants. Although guidelines have been proposed, there is not yet an established set of usability heuristics to guide and evaluate conversational agent design. In this paper, we propose a set of heuristics for conversational agents adapted from Nielsen’s heuristics and based on expert feedback. We then validate the heuristics through two rounds of evaluations conducted by participants on two conversational agents, one chatbot and one voice-based personal assistant. We find that, when using our heuristics to evaluate both interfaces, evaluators were able to identify more usability issues than when using Nielsen’s heuristics. We propose that our heuristics successfully identify issues related to dialogue content, interaction design, help and guidance, human-like characteristics, and data privacy.",119
2024,"Mining, Assessing, and Improving Arguments in NLP and the Social Sciences","Gabriella Lapesa, Eva Maria Vecchi, Serena Villata, Henning Wachsmuth",LREC,NLP,"Computational argumentation is an interdisciplinary research field, connecting Natural Language Processing (NLP) to other disciplines such as the social sciences. The focus of recent research has concentrated on argument quality assessment: what makes an argument good or bad? We present a tutorial which is an updated edition of the EACL 2023 tutorial presented by the same authors. As in the previous version, the tutorial will have a strong interdisciplinary and interactive nature, and will be structured along three main coordinates: (1) the notions of argument quality (AQ) across disciplines (how do we recognize good and bad arguments?), with a particular focus on the interface between Argument Mining (AM) and Deliberation Theory; (2) the modeling of subjectivity (who argues to whom; what are their beliefs?); and (3) the generation of improved arguments (what makes an argument better?). The tutorial will also touch upon a series of topics that are particularly relevant for the LREC-COLING audience (the issue of resource quality for the assessment of AQ; the interdisciplinary application of AM and AQ in a text-as-data approach to Political Science), in line with the developments in NLP (LLMs for AQ assessment), and relevant for the societal applications of AQ assessment (bias and debiasing). We will involve the participants in two annotation studies on the assessment and the improvement of quality.",6
2022,Scientia Potentia Est—On the Role of Knowledge in Computational Argumentation,"Anne Lauscher, Henning Wachsmuth, Iryna Gurevych, Goran Glavaš",TACL,NLP,"Despite extensive research efforts in recent years, computational argumentation (CA) remains one of the most challenging areas of natural language processing. The reason for this is the inherent complexity of the cognitive processes behind human argumentation, which integrate a plethora of different types of knowledge, ranging from topic-specific facts and common sense to rhetorical knowledge. The integration of knowledge from such a wide range in CA requires modeling capabilities far beyond many other natural language understanding tasks. Existing research on mining, assessing, reasoning over, and generating arguments largely acknowledges that much more knowledge is needed to accurately model argumentation computationally. However, a systematic overview of the types of knowledge introduced in existing CA models is missing, hindering targeted progress in the field. Adopting the operational definition of knowledge as any task-relevant normative information not provided as input, the survey paper at hand fills this gap by (1) proposing a taxonomy of types of knowledge required in CA tasks, (2) systematizing the large body of CA work according to the reliance on and exploitation of these knowledge types for the four main research areas in CA, and (3) outlining and discussing directions for future research efforts in CA.",30
2017,Using argumentative structure to interpret debates in online deliberative democracy and erulemaking,"John Lawrence, Joonsuk Park, Katarzyna Budzynska, Claire Cardie, Barbara Konat, Chris Reed",ACM Transactions on Internet Technology,Computer Science,"Governments around the world are increasingly utilising online platforms and social media to engage with, and ascertain the opinions of, their citizens. Whilst policy makers could potentially benefit from such enormous feedback from society, they first face the challenge of making sense out of the large volumes of data produced. In this article, we show how the analysis of argumentative and dialogical structures allows for the principled identification of those issues that are central, controversial, or popular in an online corpus of debates. Although areas such as controversy mining work towards identifying issues that are a source of disagreement, by looking at the deeper argumentative structure, we show that a much richer understanding can be obtained. We provide results from using a pipeline of argument-mining techniques on the debate corpus, showing that the accuracy obtained is sufficient to automatically identify those issues that are key to the discussion, attracting proportionately more support than others, and those that are divisive, attracting proportionately more conflicting viewpoints. 2017 Copyright is held by the owner/author(s).",38
2019,Argument Mining: A Survey,"John Lawrence, Chris Reed",Computational Linguistics,NLP,"Argument mining is the automatic identification and extraction of the structure of inference and reasoning expressed as arguments presented in natural language. Understanding argumentative structure makes it possible to determine not only what positions people are adopting, but also why they hold the opinions they do, providing valuable insights in domains as diverse as financial market prediction and public relations. This survey explores the techniques that establish the foundations for argument mining, provides a review of recent advances in argument mining techniques, and discusses the challenges faced in automatically extracting a deeper understanding of reasoning expressed in language in general.",604
2021,Conversations Are Not Flat: Modeling the Dynamic Information Flow across Dialogue Utterances,"Zekang Li, Jinchao Zhang, Zhengcong Fei, Yang Feng, Jie Zhou",ACL,NLP,"Nowadays, open-domain dialogue models can generate acceptable responses according to the historical context based on the large-scale pre-trained language models. However, they generally concatenate the dialogue history directly as the model input to predict the response, which we named as the flat pattern and ignores the dynamic information flow across dialogue utterances. In this work, we propose the DialoFlow model, in which we introduce a dynamic flow mechanism to model the context flow, and design three training objectives to capture the information dynamics across dialogue utterances by addressing the semantic influence brought about by each utterance in large-scale pre-training. Experiments on the multi-reference Reddit Dataset and DailyDialog Dataset demonstrate that our DialoFlow significantly outperforms the DialoGPT on the dialogue generation task. Besides, we propose the Flow score, an effective automatic metric for evaluating interactive human-bot conversation quality based on the pre-trained DialoFlow, which presents high chatbot-level correlation (r=0.9) with human ratings among 11 chatbots. Code and pre-trained models will be public.",61
2011,"Critical thinking in asynchronous online discussion: An
investigation of student facilitation techniques","Lim, Sze Chung Raymond; Cheung, Wing Sum; Hew, Khe Foon",New Horizons in Education ,Social Science,"In the last decade, asynchronous online discussion forums have become a primary focus of many educational researchers. Some advocates believed that the process of typing out messages in itself can promote in-depth critical thinking skills. Nevertheless, empirical research has not provided much support for this claim in natural settings. In fact, many previous studies have found that students do not necessary exhibit in-depth critical thinking in online discussions. Aims: To investigate the types of facilitation techniques exhibited by student facilitators, and how these techniques might influence in-depth levels of critical thinking in asynchronous online discussion forums. Sample: Participants of the study were ten education major students at an Asia-Pacific university. Method: An exploratory qualitative case study methodology was employed. Data were collected from the students' online discussion postings and interviews. The top 30% of discussion forums in terms of the most number of in-depth critical thinking incidences were first identified. Next, the bottom 30% forums were identified as the lower-level critical thinking group. Results: In the case of the top 30% forums, showing appreciation, questioning, expressing agreements, and providing opinions or explanations were among the most prevalent facilitation techniques used, while in the case of the bottom 30% forums, the most common facilitation techniques merely included showing acknowledgement or appreciation and inviting feedback or comments. Conclusion: The findings suggest that student facilitators should perhaps focus on three facilitation techniques, specifically questioning, expressing agreements, and providing opinions or explanations to foster in-depth level of critical thinking. The findings also suggest that it may serve student facilitators well to employ a variety of facilitation techniques rather than just utilise a few preferred ones in order to achieve higher levels of critical thinking.",71
2023,Unified Conversational Models with System-Initiated Transitions between Chit-Chat and Task-Oriented Dialogues,"Ye Liu, Stefan Ultes, Wolfgang Minker, Wolfgang Maier","International Conference on Conversational User Interfaces",Computer Science,"Spoken dialogue systems (SDSs) have been separately developed under two different categories, task-oriented and chit-chat. The former focuses on achieving functional goals and the latter aims at creating engaging social conversations without special goals. Creating a unified conversational model that can engage in both chit-chat and task-oriented dialogue is a promising research topic in recent years. However, the potential “initiative” that occurs when there is a change between dialogue modes in one dialogue has rarely been explored. In this work, we investigate two kinds of dialogue scenarios, one starts from chit-chat implicitly involving task-related topics and finally switching to task-oriented requests; the other starts from task-oriented interaction and eventually changes to casual chat after all requested information is provided. We contribute two efficient prompt models which can proactively generate a transition sentence to trigger system-initiated transitions in a unified dialogue model. One is a discrete prompt model trained with two discrete tokens, the other one is a continuous prompt model using continuous prompt embeddings automatically generated by a classifier. We furthermore show that the continuous prompt model can also be used to guide the proactive transitions between particular domains in a multi-domain task-oriented setting.",6
2022,Coding empathy in dialogue,"Fabrizio Macagno, 
Chrysi Rapanta, 
Elisabeth Mayweg-Paus, 
Mercè Garcia-Milà",Journal of Pragmatics,"Social Science, Pragmatics","Empathy, broadly defined as the ability to experience another's emotions and perceptions, is one of the major attitudes and actions underpinning an individual's participation in dialogue across diversity. The goal of this methodological paper is to operationalize empathy as a discursive construct, manifested in children and adolescent dialogic interactions. A coding scheme is developed based on three distinct steps. First, a review of the operational definitions of empathy is carried out, to capture how its related values, skills, and dispositions have been detected thus far. Second, the definitional elements resulting from this overview are represented in the dialogical notion of other-orientedness, which can be manifested, actually and potentially, in discourse. Moves are distinguished in 8 categories based on their disposition to be potentially other-oriented (dialogicity), which becomes actually manifested depending on their relevance to the discourse they are used in. Dialogicity and relevance are captured by the coding scheme proposed in this paper, which is validated and used to illustrate how it can reveal dialogical empathy and the development of common ground in interactions.",21
2024,LLMs of Catan: Exploring Pragmatic Capabilities of Generative Chatbots Through Prediction and Classification of Dialogue Acts in Boardgames’ Multi-party Dialogues,"Andrea Martinenghi, Gregor Donabauer, Simona Amenta, Sathya Bursic, Mathyas Giudici, Udo Kruschwitz, Franca Garzotto, Dimitri Ognibene",Workshop on Games and Natural Language Processing,NLP,"Human language interactions involve complex processes beyond pure information exchange, for example, actions aimed at influencing beliefs and behaviors within a communicative context. In this paper, we propose to investigate the dialogue understanding capabilities of large language models (LLMs), particularly in multi-party settings, where challenges like speaker identification and turn-taking are common. Through experiments on the game-based STAC dataset, we explore zero and few-shot learning approaches for dialogue act classification in a multi-party game setting. Our intuition is that LLMs may excel in tasks framed through examples rather than formal descriptions, influenced by a range of pragmatic features like information presentation order in prompts and others. We also explore the models’ predictive abilities regarding future dialogue acts and study integrating information on dialogue act sequences to improve predictions. Our findings suggest that ChatGPT can keep up with baseline models trained from scratch for classification of certain dialogue act types but also reveal biases and limitations associated with the approach. These insights can be valuable for the development of multi-party chatbots and we try to point out directions for future research towards nuanced understanding and adaptation in diverse conversational contexts",3
2019,Spread of Hate Speech in Online Social Media,"Binny Mathew, Ritam Dutt, Pawan Goyal, Animesh Mukherjee","ACM Conference on Web Science
",NLP,"Hate speech is considered to be one of the major issues currently plaguing the online social media. With online hate speech culminating in gruesome scenarios like the Rohingya genocide in Myanmar, anti-Muslim mob violence in Sri Lanka, and the Pittsburgh synagogue shooting, there is a dire need to understand the dynamics of user interaction that facilitate the spread of such hateful content. In this paper, we perform the first study that looks into the diffusion dynamics of the posts made by hateful and non-hateful users on Gab (Gab.com). We collect a massive dataset of 341K users with 21M posts and investigate the diffusion of the posts generated by hateful and non-hateful users. We observe that the content generated by the hateful users tend to spread faster, farther and reach a much wider audience as compared to the content generated by normal users. We further analyze the hateful and non-hateful users on the basis of their account and network characteristics. An important finding is that the hateful users are far more densely connected among themselves. Overall, our study provides the first cross-sectional view of how hateful users diffuse hate content in online social media.",461
2024,ECoh: Turn-level Coherence Evaluation for Multilingual Dialogues,"John Mendonca, Isabel Trancoso, Alon Lavie",Annual Meeting of the Special Interest Group on Discourse and Dialogue,NLP,"Despite being heralded as the new standard for dialogue evaluation, the closed-source nature of GPT-4 poses challenges for the community. Motivated by the need for lightweight, open source, and multilingual dialogue evaluators, this paper introduces GenResCoh (Generated Responses targeting Coherence). GenResCoh is a novel LLM generated dataset comprising over 130k negative and positive responses and accompanying explanations seeded from XDailyDialog and XPersona covering English, French, German, Italian, and Chinese. Leveraging GenResCoh, we propose ECoh (Evaluation of Coherence), a family of evaluators trained to assess response coherence across multiple languages. Experimental results demonstrate that ECoh achieves multilingual detection capabilities superior to the teacher model (GPT-3.5-Turbo) on GenResCoh, despite being based on a much smaller architecture. Furthermore, the explanations provided by ECoh closely align in terms of quality with those generated by the teacher model.",?
2024,Are Large Language Models Reliable Argument Quality Annotators?,"Nailia Mirzakhmedova, Marcel Gohsen, Chia Hao Chang, Benno Stein",Robust Argumentation Machines ,Computer Science,"Evaluating the quality of arguments is a crucial aspect of any system leveraging argument mining. However, it is a challenge to obtain reliable and consistent annotations regarding argument quality, as this usually requires domain-specific expertise of the annotators. Even among experts, the assessment of argument quality is often inconsistent due to the inherent subjectivity of this task. In this paper, we study the potential of using state-of-the-art large language models (LLMs) as proxies for argument quality annotators. To assess the capability of LLMs in this regard, we analyze the agreement between model, human expert, and human novice annotators based on an established taxonomy of argument quality dimensions. Our findings highlight that LLMs can produce consistent annotations, with a moderately high agreement with human experts across most of the quality dimensions. Moreover, we show that using LLMs as additional annotators can significantly improve the agreement between annotators. These results suggest that LLMs can serve as a valuable tool for automated argument quality assessment, thus streamlining and accelerating the evaluation of large argument datasets .",7
2022,When AI moderates online content: Effects of human collaboration and interactive transparency on user trust,"Maria D Molina, S Shyam Sundar",Journal of Computer-Mediated Communication,Computational Social Science,"Given the scale of user-generated content online, the use of artificial intelligence (AI) to flag problematic posts is inevitable, but users do not trust such automated moderation of content. We explore if (a) involving human moderators in the curation process and (b) affording ""interactive transparency,""wherein users participate in curation, can promote appropriate reliance on AI. We test this through a 3 (Source: AI, Human, Both) × 3 (Transparency: No Transparency, Transparency-Only, Interactive Transparency) × 2 (Classification Decision: Flagged, Not Flagged) between-subjects online experiment (N = 676) involving classification of hate speech and suicidal ideation. We discovered that users trust AI for the moderation of content just as much as humans, but it depends on the heuristic that is triggered when they are told AI is the source of moderation. We also found that allowing users to provide feedback to the algorithm enhances trust by increasing user agency.",62
2023,Language Artificial Intelligences' Communicative Performance Quantified Through the Gricean Conversation Theory,"Yunju Nam, Hyenyeong Chung, Upyong Hong","Cyberpsychology, Behavior, and Social Networking",Computational Social Science,"This study pragmatically investigates an artificial intelligence (AI) speaker (AIS)'s verbal communicative performance based on real AI–human conversation data. Specifically, this study explores Grice's conversation theory, which enables the categorization of an AIS's mistaken utterances as violations of specific conversational maxims. Twenty native Korean-speaking participants recorded at least 50 conversations with Kakao Mini AISs, provided by Daum Kakao, Inc., in Korea. Each conversation, either for information sharing or as daily dialogue, was required to contain at least two turn-taking instances. A total of 1,026 recorded dialogues were decomposed into adjacency pairs based on turn-taking. The dialogues were arranged into 3,365 adjacency pairs, and each pair was then classified as a conversational success or failure based on whether the AIS answered the user's utterance appropriately. Language users' evaluations of the AIS's mistaken expressions were also quantified via an additional acceptability rating test with 1,024 adjacency pairs. The overall results indicate that Grice's “maxim of relation” is most frequently flouted by AISs and is considered to be the least natural to language users. These findings suggest that to improve AISs' natural communication capacity, more detailed AI algorithms that generate utterances relevant to either the partner's preceding utterance or a broader conversational context should be created. Although the verbal communicative capacities of the AIS we test are substantially overtaken by those of recent large language models, such as generative pretrained transformer, the pragmatic evaluation described in the current study will remain useful for more precise linguistic quantification of current/future language AI's communicative performance/competence.",5
2021,An intelligent knowledge-based chatbot for customer service,"Eric W.T. Ngai, 
Maggie C.M. Lee, 
Mei Luo, 
Patrick S.L. Chan, 
Tenglu Liang",Electronic Commerce Research and Applications,Computer Science,"This study proposes an intelligent knowledge-based conversational agent system architecture to support customer services in e-commerce sales and marketing. A pilot implementation of a chatbot for customer services is reported in a leading women’s intimate apparel manufacturing firm. The proposed system incorporates various emerging technologies, including web crawling, natural language processing, knowledge bases, and artificial intelligence. In this study, a prototype system is built in a real-world setting. The results of the system prototype evaluation are satisfactory and support the contention that the system is effective. The study also discusses the challenges and lessons learned during system implementation and the theoretical and managerial implications of this study",128
2016,Conversational Markers of Constructive Discussions,"Vlad Niculae, Cristian Danescu-Niculescu-Mizil",NAACL,NLP,"Group discussions are essential for organizing every aspect of modern life, from faculty meetings to senate debates, from grant review panels to papal conclaves. While costly in terms of time and organization effort, group discussions are commonly seen as a way of reaching better decisions compared to solutions that do not require coordination between the individuals (e.g. voting)—through discussion, the sum becomes greater than the parts. However, this assumption is not irrefutable: anecdotal evidence of wasteful discussions abounds, and in our own experiments we find that over 30% of discussions are unproductive. We propose a framework for analyzing conversational dynamics in order to determine whether a given task-oriented discussion is worth having or not. We exploit conversational patterns reflecting the flow of ideas and the balance between the participants, as well as their linguistic choices. We apply this framework to conversations naturally occurring in an online collaborative world exploration game developed and deployed to support this research. Using this setting, we show that linguistic cues and conversational patterns extracted from the first 20 seconds of a team discussion are predictive of whether it will be a wasteful or a productive one.",64
2023,Generative Agents: Interactive Simulacra of Human Behavior,"Joon Sung Park, Joseph C. O'Brien, Carrie J. Cai, Meredith Ringel Morris, Percy Liang, Michael S. Bernstein","ACM Symposium on User Interface Software
and Technology",Computer Science,"Believable proxies of human behavior can empower interactive applications ranging from immersive environments to rehearsal spaces for interpersonal communication to prototyping tools. In this paper, we introduce generative agents: computational software agents that simulate believable human behavior. Generative agents wake up, cook breakfast, and head to work; artists paint, while authors write; they form opinions, notice each other, and initiate conversations; they remember and reflect on days past as they plan the next day. To enable generative agents, we describe an architecture that extends a large language model to store a complete record of the agent’s experiences using natural language, synthesize those memories over time into higher-level reflections, and retrieve them dynamically to plan behavior. We instantiate generative agents to populate an interactive sandbox environment inspired by The Sims, where end users can interact with a small town of twenty-five agents using natural language. In an evaluation, these generative agents produce believable individual and emergent social behaviors. For example, starting with only a single user-specified notion that one agent wants to throw a Valentine’s Day party, the agents autonomously spread invitations to the party over the next two days, make new acquaintances, ask each other out on dates to the party, and coordinate to show up for the party together at the right time. We demonstrate through ablation that the components of our agent architecture—observation, planning, and reflection—each contribute critically to the believability of agent behavior. By fusing large language models with computational interactive agents, this work introduces architectural and interaction patterns for enabling believable simulations of human behavior.",36
2022,Social Simulacra: Creating Populated Prototypes for Social Computing Systems,"Joon Sung Park, Lindsay Popowski, Carrie Cai, Meredith Ringel Morris, Percy Liang, Michael S. Bernstein","ACM Symposium on User Interface Software
and Technology",Computer Science,"Social computing prototypes probe the social behaviors that may arise in an envisioned system design. This prototyping practice is currently limited to recruiting small groups of people. Unfortunately, many challenges do not arise until a system is populated at a larger scale. Can a designer understand how a social system might behave when populated, and make adjustments to the design before the system falls prey to such challenges? We introduce social simulacra, a prototyping technique that generates a breadth of realistic social interactions that may emerge when a social computing system is populated. Social simulacra take as input the designer’s description of a community’s design—goal, rules, and member personas—and produce as output an instance of that design with simulated behavior, including posts, replies, and anti-social behaviors. We demonstrate that social simulacra shift the behaviors that they generate appropriately in response to design changes, and that they enable exploration of “what if?” scenarios where community members or moderators intervene. To power social simulacra, we contribute techniques for prompting a large language model to generate thousands of distinct community members and their social interactions with each other; these techniques are enabled by the observation that large language models’ training data already includes a wide variety of positive and negative behavior on social media platforms. In evaluations, we show that participants are often unable to distinguish social simulacra from actual community behavior and that social computing designers successfully refine their social computing designs when using social simulacra.",269
2012,Facilitative moderation for online participation in eRulemaking,"Joonsuk Park, Sally Klingel, Claire Cardie, Mary Newhart, Cynthia Farina, Joan-Josep Vallbé",Annual International Conference on Digital Government Research,Computational Social Science,"This paper describes the use of facilitative moderation strategies in an online rulemaking public participation system. Rulemaking is one of the U. S. government's most important policymaking methods. Although broad transparency and participation rights are part of its legal structure, significant barriers prevent effective engagement by many groups of interested citizens. Regulation Room, an experimental open-government partnership between academic researchers and government agencies, is a socio-technical participation system that uses multiple methods to lower potential barriers to broader participation. To encourage effective individual comments and productive group discussion in Regulation Room, we adapt strategies for facilitative human moderation originating from social science research in deliberative democracy and alternative dispute resolution [24, 1, 18, 14] for use in the demanding online participation setting of eRulemaking. We develop a moderation protocol, deploy it in ""live"" Department of Transportation (DOT) rulemakings, and provide an initial analysis of its use through a manual coding of all moderator interventions with respect to the protocol. We then investigate the feasibility of automating the moderation protocol: we employ annotated data from the coding project to train machine learning-based classifiers to identify places in the online discussion where human moderator intervention is required. Though the trained classifiers only marginally outperform the baseline, the improvement is statistically significant in spite of limited data and a very basic feature set, which is a promising result.",26
2020,Defining and Quantifying Conversation Quality in Spontaneous Interactions,"Navin Raj Prabhu, Chirag Raman, Hayley Hung","International Conference on Multimodal Interaction",Computer Science,"Social interactions in general are multifaceted and there exists a wide set of factors and events that influence them. In this paper, we quantify social interactions with a holistic viewpoint on individual experiences, particularly focusing on non-task-directed spontaneous interactions. To achieve this, we design a novel perceived measure, the perceived Conversation Quality, which intends to quantify spontaneous interactions by accounting for several socio-dimensional aspects of individual experiences.
To further quantitatively study spontaneous interactions, we devise a questionnaire which measures the perceived Conversation Quality, at both the individual- and at the group- level. Using the questionnaire, we collected perceived annotations for conversation quality in a publicly available dataset using naive annotators. The results of the analysis performed on the distribution and the inter-annotator agreeability shows that naive annotators tend to agree less in cases of low conversation quality samples, especially while annotating for group-level conversation quality.",17
2024,Can Language Models Recognize Convincing Arguments?,"Paula Rescala, Manoel Horta Ribeiro, Tiancheng Hu, Robert West",EMNLP,NLP,"The capabilities of large language models (LLMs) have raised concerns about their potential to create and propagate convincing narratives. Here, we study their performance in detecting convincing arguments to gain insights into LLMs’ persuasive capabilities without directly engaging in experimentation with humans. We extend a dataset by Durmus and Cardie (2018) with debates, votes, and user traits and propose tasks measuring LLMs’ ability to (1) distinguish between strong and weak arguments, (2) predict stances based on beliefs and demographic characteristics, and (3) determine the appeal of an argument to an individual based on their traits. We show that LLMs perform on par with humans in these tasks and that combining predictions from different LLMs yields significant performance gains, surpassing human performance. The data and code released with this paper contribute to the crucial effort of continuously evaluating and monitoring LLMs’ capabilities and potential impact. (https://go.epfl.ch/persuasion-llm)",17
2018,The possibilities and limits to dialogue,"Reuben Rose-Redwood redwood@uvic.ca, Rob Kitchin, Lauren Rickards, Ugo Rossi, Ayona Datta, and Jeremy Crampton",Dialogues in Human Geography,Social Science,"In this article, we explore the nature, value, and challenges of dialogue both within and outside the academy. After considering the possibilities and limits to dialogue, we divide our analysis into three sections, first discussing dialogue as a form of embodied action, next examining dialogue as a means of enacting a critically affirmative politics, and finally exploring the challenges of engaging in dialogue as a way of practicing public geographies. In each case, we raise a number of questions concerning the potential of, and limitations to, dialogue in an age of increasing social tensions and political divides. We conclude by suggesting that although there are times when dialogical disengagement is warranted if the conditions of possibility for meaningful dialogue are unfulfilled, scholarly dialogue continues to play an important role in fostering spaces of mutual engagement in a polarized age.",68
2023,The Goldilocks of Pragmatic Understanding: Fine-Tuning Strategy Matters for Implicature Resolution by LLMs,"Laura Ruis, Akbir Khan, Stella Biderman, Sara Hooker, Tim Rocktäschel, Edward Grefenstette",NeurIPS,"Computer Science, NLP","Despite widespread use of LLMs as conversational agents, evaluations of performance fail to capture a crucial aspect of communication: interpreting language in
context—incorporating its pragmatics. Humans interpret language using beliefs
and prior knowledge about the world. For example, we intuitively understand
the response “I wore gloves” to the question “Did you leave fingerprints?” as
meaning “No”. To investigate whether LLMs have the ability to make this type
of inference, known as an implicature, we design a simple task and evaluate four
categories of widely used state-of-the-art models. We find that, despite only evaluating on utterances that require a binary inference (yes or no), models in three of
these categories perform close to random. However, LLMs instruction-tuned at
the example-level perform significantly better. These results suggest that certain
fine-tuning strategies are far better at inducing pragmatic understanding in models.
We present our findings as the starting point for further research into evaluating
how LLMs interpret language in context and to drive the development of more
pragmatic and useful models of human discourse.",27
2016," Discussion. dialogue, and discourse| doing the talk: Discussion, dialogue, and discourse in action","Uta Russmann, Anne B. Lane",International Journal of Communication,"Social Science, Communication","Discussion, dialogue, and discourse have long been regarded as important concepts across a range of communication-related disciplines such as public relations, organizational communication, interpersonal communication, and strategic management. These concepts are becoming even more significant with the increasing use of social media and other forms of online communication by organizations and their publics/stakeholders/citizens. This Special Section of the International Journal of Communication presents theoretical frameworks and propositions, methodological approaches, and empirical findings that add to the understanding of discussion, dialogue, and discourse.",3
2021,Cross-Policy Compliance Detection via Question Answering,"Marzieh Saeidi, Majid Yazdani, Andreas Vlachos",EMNLP,NLP,"Policy compliance detection is the task of ensuring that a scenario conforms to a policy (e.g. a claim is valid according to government rules or a post in an online platform conforms to community guidelines). This task has been previously instantiated as a form of textual entailment, which results in poor accuracy due to the complexity of the policies. In this paper we propose to address policy compliance detection via decomposing it into question answering, where questions check whether the conditions stated in the policy apply to the scenario, and an expression tree combines the answers to obtain the label. Despite the initial upfront annotation cost, we demonstrate that this approach results in better accuracy, especially in the cross-policy setup where the policies during testing are unseen in training. In addition, it allows us to use existing question answering models pre-trained on existing large datasets. Finally, it explicitly identifies the information missing from a scenario in case policy compliance cannot be determined. We conduct our experiments using a recent dataset consisting of government policies, which we augment with expert annotations and find that the cost of annotating question answering decomposition is largely offset by improved inter-annotator agreement and speed.",4
2020,Social Bias Frames: Reasoning about Social and Power Implications of Language,"Maarten Sap, Saadia Gabriel, Lianhui Qin, Dan Jurafsky, Noah A. Smith, Yejin Choi",ACL,NLP,"Language has the power to reinforce stereotypes and project social biases onto others. At the core of the challenge is that it is rarely what is stated explicitly, but rather the implied meanings, that frame people’s judgments about others. For example, given a statement that “we shouldn’t lower our standards to hire more women,” most listeners will infer the implicature intended by the speaker - that “women (candidates) are less qualified.” Most semantic formalisms, to date, do not capture such pragmatic implications in which people express social biases and power differentials in language. We introduce Social Bias Frames, a new conceptual formalism that aims to model the pragmatic frames in which people project social biases and stereotypes onto others. In addition, we introduce the Social Bias Inference Corpus to support large-scale modelling and evaluation with 150k structured annotations of social media posts, covering over 34k implications about a thousand demographic groups. We then establish baseline approaches that learn to recover Social Bias Frames from unstructured text. We find that while state-of-the-art neural models are effective at high-level categorization of whether a given statement projects unwanted social bias (80% F1), they are not effective at spelling out more detailed explanations in terms of Social Bias Frames. Our study motivates future work that combines structured pragmatic inference with commonsense reasoning on social implications.",515
2024,"""Community Guidelines Make this the Best Party on the Internet"": An In-Depth Study of Online Platforms' Content Moderation Policies","Brennan Schaffner, Arjun Nitin Bhagoji, Siyuan Cheng, Jacqueline Mei, Jay L Shen, Grace Wang, Marshini Chetty, Nick Feamster, Genevieve Lakier, Chenhao Tan","Conference on Human Factors in Computing Systems",Computer Science,"Moderating user-generated content on online platforms is crucial for balancing user safety and freedom of speech. Particularly in the United States, platforms are not subject to legal constraints prescribing permissible content. Each platform has thus developed bespoke content moderation policies, but there is little work towards a comparative understanding of these policies across platforms and topics. This paper presents the first systematic study of these policies from the 43 largest online platforms hosting user-generated content, focusing on policies around copyright infringement, harmful speech, and misleading content. We build a custom web-scraper to obtain policy text and develop a unified annotation scheme to analyze the text for the presence of critical components. We find significant structural and compositional variation in policies across topics and platforms, with some variation attributable to disparate legal groundings. We lay the groundwork for future studies of ever-evolving content moderation policies and their impact on users.",4
2022,Proactive Moderation of Online Discussions: Existing Practices and the Potential for Algorithmic Support,"Charlotte Schluger, Jonathan P. Chang, Cristian Danescu-Niculescu-Mizil, Karen Levy",ACM on Human-Computer Interaction,Computer Science,"To address the widespread problem of uncivil behavior, many online discussion platforms employ human moderators to take action against objectionable content, such as removing it or placing sanctions on its authors. Thisreactive paradigm of taking action against already-posted antisocial content is currently the most common form of moderation, and has accordingly underpinned many recent efforts at introducing automation into the moderation process. Comparatively less work has been done to understand other moderation paradigms---such as proactively discouraging the emergence of antisocial behavior rather than reacting to it---and the role algorithmic support can play in these paradigms. In this work, we investigate such a proactive framework for moderation in a case study of a collaborative setting: Wikipedia Talk Pages. We employ a mixed methods approach, combining qualitative and design components for a holistic analysis. Through interviews with moderators, we find that despite a lack of technical and social support, moderators already engage in a number of proactive moderation behaviors, such as preemptively intervening in conversations to keep them on track. Further, we explore how automation could assist with this existing proactive moderation workflow by building a prototype tool, presenting it to moderators, and examining how the assistance it provides might fit into their workflow. The resulting feedback uncovers both strengths and drawbacks of the prototype tool and suggests concrete steps towards further developing such assisting technology so it can most effectively support moderators in their existing proactive moderation workflow.",27
2024,Fora: A corpus and framework for the study of facilitated dialogue,"Hope Schroeder, Deb Roy, Jad Kabbara",ACL,NLP,"Facilitated dialogue is increasingly popular as a method of civic engagement and as a method for gathering social insight, but resources for its study are scant. We present Fora, a unique collection of annotated facilitated dialogues. We compile 262 facilitated conversations that were hosted with partner organizations seeking to engage their members and surface insights regarding issues like education, elections, and public health, primarily through the sharing of personal experience. Alongside this corpus of 39,911 speaker turns, we present a framework for the analysis of facilitated dialogue. We taxonomize key personal sharing behaviors and facilitation strategies in the corpus, annotate a 25% sample (10,000+ speaker turns) of the data accordingly, and evaluate and establish baselines on a number of tasks essential to the identification of these phenomena in dialogue. We describe the data, and relate facilitator behavior to turn-taking and participant sharing. We outline how this research can inform future work in understanding and improving facilitated dialogue, parsing spoken conversation, and improving the behavior of dialogue agents.",2
2019,What makes a good conversation? How controllable attributes affect human judgments,"Abigail See, Stephen Roller, Douwe Kiela, Jason Weston",NAACL,NLP,"A good conversation requires balance – between simplicity and detail; staying on topic and changing it; asking questions and answering them. Although dialogue agents are commonly evaluated via human judgments of overall quality, the relationship between quality and these individual factors is less well-studied. In this work, we examine two controllable neural text generation methods, conditional training and weighted decoding, in order to control four important attributes for chit-chat dialogue: repetition, specificity, response-relatedness and question-asking. We conduct a large-scale human evaluation to measure the effect of these control parameters on multi-turn interactive conversations on the PersonaChat task. We provide a detailed analysis of their relationship to high-level aspects of conversation, and show that by controlling combinations of these variables our models obtain clear improvements in human quality judgments.",261
2020,Reconsidering Self-Moderation: the Role of Research in Supporting Community-Based Models for Online Content Moderation,Joseph Seering,ACM on Human-Computer Interaction,Computer Science,"Research in online content moderation has a long history of exploring different forms that moderation can take, including both user-driven moderation models on community-based platforms like Wikipedia, Facebook Groups, and Reddit, and centralized corporate moderation models on platforms like Twitter and Instagram. In this work I review different approaches to moderation research with the goal of providing a roadmap for researchers studying community self-moderation. I contrast community-based moderation research with platforms and policies-focused moderation research, and argue that the former has an important role to play in shaping discussions about the future of online moderation. I provide six guiding questions for future research that, if answered, can support the development of a form of user-driven moderation that is widely implementable across a variety of social spaces online, offering an alternative to the corporate moderation models that dominate public debate and discussion.",155
2024,Reliable LLM-based User Simulator for Task-Oriented Dialogue Systems,"Ivan Sekulic, Silvia Terragni, Victor Guimarães, Nghia Khau, Bruna Guedes, Modestas Filipavicius, Andre Ferreira Manso, Roland Mathis",Workshop on Simulating Conversational Intelligence in Chat ,NLP,"In the realm of dialogue systems, user simulation techniques have emerged as a game-changer, redefining the evaluation and enhancement of task-oriented dialogue (TOD) systems. These methods are crucial for replicating real user interactions, enabling applications like synthetic data augmentation, error detection, and robust evaluation. However, existing approaches often rely on rigid rule-based methods or on annotated data. This paper introduces DAUS, a Domain-Aware User Simulator. Leveraging large language models, we fine-tune DAUS on real examples of task-oriented dialogues. Results on two relevant benchmarks showcase significant improvements in terms of user goal fulfillment. Notably, we have observed that fine-tuning enhances the simulator’s coherence with user goals, effectively mitigating hallucinations—a major source of inconsistencies in simulator responses.",11
2024,Examining Human-AI Collaboration for Co-Writing Constructive Comments Online,"Farhana Shahid, Maximilian Dittgen, Mor Naaman, Aditya Vashistha",Arxiv,NLP,"This paper examines how large language models (LLMs) can help people write constructive comments in online debates on divisive social issues and whether the notions of constructiveness vary across cultures. Through controlled experiments with 600 participants from India and the US, who reviewed and wrote constructive comments on online threads on Islamophobia and homophobia, we found potential misalignment in how LLMs and humans perceive constructiveness in online comments. While the LLM was more likely to view dialectical comments as more constructive, participants favored comments that emphasized logic and facts more than the LLM did. Despite these differences, participants rated LLM-generated and human-AI co-written comments as significantly more constructive than those written independently by humans. Our analysis also revealed that LLM-generated and human-AI co-written comments exhibited more linguistic features associated with constructiveness compared to human-written comments on divisive topics. When participants used LLMs to refine their comments, the resulting comments were longer, more polite, positive, less toxic, and more readable, with added argumentative features that retained the original intent but occasionally lost nuances. Based on these findings, we discuss ethical and design considerations in using LLMs to facilitate constructive discourse online.",?
2024,BERT and LLM-Based Multivariate Hate Speech Detection on Twitter: Comparative Analysis and Superior Performance,"Xiaohou Shi, Jiahao Liu & Yaqi Song ",Artificial Intelligence and Machine Learning,"Computer Science, NLP","The detection of toxic and hate speech in online social media is becoming increasingly necessary due to its prevalence and the potentially harmful consequences it can cause. Previous research has demonstrated the vital role that machine learning and natural language processing models have in identifying inappropriate language. In this study, the aim is to assess the viability of BERT for accurately predicting multivariate classifications related to hate speech on Twitter. The analysis will be conducted using the Twitter hate speech dataset. BERT has demonstrated exceptional performance in numerous areas of NLP, making it a potentially superior alternative to traditional machine learning approaches. Experiments were performed on the same dataset using 1-layer BERT, 2-layers BERT, and logistic regression models for both training and prediction purposes. The results demonstrate that the 2-layer BERT produces an accuracy of 85%. Additionally, we incorporated transfer learning techniques by leveraging a Large Language model GPT-3 and data augmentation strategies to further enhance model performance. This experiment reached a higher accuracy of 88%. As this is a multivariate classification problem with an asymmetrical dataset, we anticipate BERT and GPT-3 will achieve greater accuracy for the binary classification problem of identifying hate speech. These findings enhance the comprehension of hate speech detection in online material and the implications of various modeling approaches",5
2023,Opportunities and Risks of LLMs for Scalable Deliberation with Polis,"Christopher T. Small, Ivan Vendrov, Esin Durmus, Hadjar Homaei, Elizabeth Barry, Julien Cornebise, Ted Suzman, Deep Ganguli, Colin Megill",Arxiv,Computer Science,"Polis is a platform that leverages machine intelligence to scale up deliberative processes. In this paper, we explore the opportunities and risks associated with applying Large Language Models (LLMs) towards challenges with facilitating, moderating and summarizing the results of Polis engagements. In particular, we demonstrate with pilot experiments using Anthropic's Claude that LLMs can indeed augment human intelligence to help more efficiently run Polis conversations. In particular, we find that summarization capabilities enable categorically new methods with immense promise to empower the public in collective meaning-making exercises. And notably, LLM context limitations have a significant impact on insight and quality of these results.
However, these opportunities come with risks. We discuss some of these risks, as well as principles and techniques for characterizing and mitigating them, and the implications for other deliberative or political systems that may employ LLMs. Finally, we conclude with several open future research directions for augmenting tools like Polis with LLMs.",29
2020,DebateVis: Visualizing Political Debates for Non-Expert Users,Laura South; Michail Schwab; Nick Beauchamp; Lu Wang; John Wihbey; Michelle A. Borkin,IEEE Visualization Conference,Computer Science,"Political debates provide an important opportunity for voters to observe candidate behavior, learn about issues, and make voting decisions. However, debates are generally broadcast late at night and last more than ninety minutes, so watching debates live can be inconvenient, if not impossible, for many potential viewers. Even voters who do watch debates may find themselves overwhelmed by a deluge of information in a substantive, issue-driven debate. Media outlets produce short summaries of debates, but these are not always effective as a method of deeply comprehending the policies candidates propose or the debate techniques they employ. In this paper we contribute reflections and results of an 18-month design study through an interdisciplinary collaboration with journalism and political science researchers. We characterize task and data abstractions for visualizing political debate transcripts for the casual user, and present a novel tool (DebateVis) to help non-expert users explore and analyze debate transcripts.",18
2024,PUB: A Pragmatics Understanding Benchmark for Assessing LLMs’ Pragmatics Capabilities,"Settaluri Sravanthi, Meet Doshi, Pavan Tankala, Rudra Murthy, Raj Dabre, Pushpak Bhattacharyya",ACL,NLP,"LLMs have demonstrated remarkable capability for understanding semantics, but their understanding of pragmatics is not well studied. To this end, we release a Pragmatics Understanding Benchmark (PUB) dataset consisting of fourteen tasks in four pragmatics phenomena, namely; Implicature, Presupposition, Reference, and Deixis. We curate high-quality test sets for each task, consisting of Multiple Choice Question Answers (MCQA). PUB includes a total of 28k data points, 6.1k are newly annotated. We evaluate nine models varying in the number of parameters and type of training. Our study reveals several key observations about the pragmatic capabilities of LLMs: 1. chat-fine-tuning strongly benefits smaller models, 2. large base models are competitive with their chat-fine-tuned counterparts, 3. there is a huge variance in performance across different pragmatics phenomena, and 4. a noticeable performance gap between human capabilities and model capabilities. We hope that PUB will enable comprehensive evaluation of LLM’s pragmatic reasoning capabilities.",23
2000,Dialogue act modeling for automatic tagging and recognition of conversational speech,"Andreas Stolcke, Klaus Ries, Noah Coccaro, Elizabeth Shriberg, Rebecca Bates, Daniel Jurafsky, Paul Taylor, Rachel Martin, Carol Van Ess-Dykema, Marie Meteer",Computational Linguistics,NLP,"We describe a statistical approach for modeling dialogue acts in conversational speech, i.e., speechact-like units such as STATEMENT, QUESTION, BACKCHANNEL, AGREEMENT, DISAGREEMENT, and APOLOGY. Our model detects and predicts dialogue acts based on lexical, collocational, and prosodic cues, as well as on the discourse coherence of the dialogue act sequence.
The dialogue model is based on treating the discourse structure of a conversation as a hidden
Markov model and the individual dialogue acts as observations emanating from the model states.
Constraints on the likely sequence of dialogue acts are modeled via a dialogue act n-gram. The
statistical dialogue grammar is combined with word n-grams, decision trees, and neural networks
modeling the idiosyncratic lexical and prosodic manifestations of each dialogue act. We develop
a probabilistic integration of speech recognition with dialogue modeling, to improve both speech
recognition and dialogue act classification accuracy. Models are trained and evaluated using a
large hand-labeled database of 1,155 conversations from the Switchboard corpus of spontaneous
human-to-human telephone speech. We achieved good dialogue act labeling accuracy (65% based
on errorful, automatically recognized words and prosody, and 71% based on word transcripts,
compared to a chance baseline accuracy of 35% and human accuracy of 84%) and a small reduction
in word recognition error. ",1684
2021,Adding Chit-Chat to Enhance Task-Oriented Dialogues,"Kai Sun, Seungwhan Moon, Paul Crook, Stephen Roller, Becka Silvert, Bing Liu, Zhiguang Wang, Honglei Liu, Eunjoon Cho, Claire Cardie",NAACL,NLP,"Existing dialogue corpora and models are typically designed under two disjoint motives: while task-oriented systems focus on achieving functional goals (e.g., booking hotels), open-domain chatbots aim at making socially engaging conversations. In this work, we propose to integrate both types of systems by Adding Chit-Chat to ENhance Task-ORiented dialogues (ACCENTOR), with the goal of making virtual assistant conversations more engaging and interactive. Specifically, we propose a Human <-> AI collaborative data collection approach for generating diverse chit-chat responses to augment task-oriented dialogues with minimal annotation effort. We then present our new chit-chat-based annotations to 23.8K dialogues from two popular task-oriented datasets (Schema-Guided Dialogue and MultiWOZ 2.1) and demonstrate their advantage over the originals via human evaluation. Lastly, we propose three new models for adding chit-chat to task-oriented dialogues, explicitly trained to predict user goals and to generate contextually relevant chit-chat responses. Automatic and human evaluations show that, compared with the state-of-the-art task-oriented baseline, our models can code-switch between task and chit-chat to be more engaging, interesting, knowledgeable, and humanlike, while maintaining competitive task performance.",78
2022,Make Reddit Great Again: Assessing Community Effects of Moderation Interventions on r/The_Donald,"Amaury Trujillo, Stefano Cresci",ACM on Human-Computer Interaction,Computer Science,"The subreddit r/The_Donald was repeatedly denounced as a toxic and misbehaving online community, reasons for which it faced a sequence of moderation interventions by Reddit administrators. It was quarantined in June 2019, restricted in February 2020, and finally banned in June 2020, but despite precursory work on the matter, the effects of this sequence of interventions are still unclear. In this work, we follow a multidimensional causal inference approach, with data containing more than 15M posts made in a time frame of 2 years, to examine the effects of such interventions inside and outside of the subreddit. We find that the interventions greatly reduced the activity of problematic users. However, the interventions also caused an increase in toxicity and led users to share more polarized and less factual news. In addition, the restriction had stronger effects than the quarantine, and core users of r/The_Donald suffered stronger effects than the rest of users. Overall, our results provide evidence that the interventions had mixed effects and paint a nuanced picture of the consequences of community-level moderation strategies. We conclude by reflecting on the challenges of policing online platforms and on the implications for the design and deployment of moderation interventions.",69
2016,Winning Arguments: Interaction Dynamics and Persuasion Strategies in Good-faith Online Discussions,"Chenhao Tan, Vlad Niculae, Cristian Danescu-Niculescu-Mizil, Lillian Lee","International Conference on World Wide Web",Computer Science,"Changing someone's opinion is arguably one of the most important challenges of social interaction. The underlying process proves difficult to study: it is hard to know how someone's opinions are formed and whether and how someone's views shift. Fortunately, ChangeMyView, an active community on Reddit, provides a platform where users present their own opinions and reasoning, invite others to contest them, and acknowledge when the ensuing discussions change their original views. In this work, we study these interactions to understand the mechanisms behind persuasion.
We find that persuasive arguments are characterized by interesting patterns of interaction dynamics, such as participant entry-order and degree of back-and-forth exchange. Furthermore, by comparing similar counterarguments to the same opinion, we show that language factors play an essential role. In particular, the interplay between the language of the opinion holder and that of the counterargument provides highly predictive cues of persuasiveness. Finally, since even in this favorable setting people may not be persuaded, we investigate the problem of determining whether someone's opinion is susceptible to being changed at all. For this more difficult task, we show that stylistic choices in how the opinion is expressed carry predictive power.",449
2024,AI can help humans find common ground in democratic deliberation,"Michael Henry Tessler, Michiel A Bakker, Daniel Jarrett, Hannah Sheahan, Martin J Chadwick, Raphael Koster, Georgina Evans, Lucy Campbell-Gillingham, Tantum Collins, David C Parkes, Matthew Botvinick, Christopher Summerfield",Science,"Artificial Intelligence, Computer Science","To act collectively, groups must reach agreement; however, this can be challenging when discussants present very different but valid opinions. Tessler et al. investigated whether artificial intelligence (AI) can help groups reach a consensus during democratic debate (see the Policy Forum by Nyhan and Titiunik). The authors trained a large language model called the Habermas Machine to serve as an AI mediator that helped small UK groups find common ground while discussing divisive political issues such as Brexit, immigration, the minimum wage, climate change, and universal childcare. Compared with human mediators, AI mediators produced more palatable statements that generated wide agreement and left groups less divided. The AI’s statements were more clear, logical, and informative without alienating minority perspectives. This work carries policy implications for AI’s potential to unify deeply divided groups. —Ekeoma Uzogara",26
2009,Facilitation and Inclusive Deliberation,MATTHIAS TRÉNEL,"Online Deliberation: Design, Research, and Practice",Social Science,"While scholars of citizen deliberation frequently consider problems that
participants face in accessing deliberative environments (see Cohen 1997),
they often fail to address a more subtle form of exclusion that occurs within
deliberative environments. As Young (2000: 53-65) explains, some participants may be marginalized during deliberation if they have lower chances
to be heard, introduce topics, make contributions, or suggest or criticize
proposals. In other words, they may face the problem of ‘internal exclusion’
(see also Habermas 1996).
To challenge this problem, facilitation may serve as an important means
for inclusive deliberation. For example, facilitators or moderators can structure group communication in a way that empowers disadvantaged participants (Fung 2004; Fulwider 2005).1 Still, evaluations of facilitation are infrequently studied (Sunwolf and Frey 2005). The study described here looks
at the effects of different types of facilitation.",49
2024,Generative AI for Pro-Democracy Platforms,"Lily L. Tsai, Alex ‘Sandy’ Pentland, Alia Braley, Nuole (Lula) Chen, José Ramón Enríquez, Anka Reuel",An MIT Exploration of Generative AI,Computational Social Science,"Online discourse faces challenges in facilitating substantive and productive political conversations. Recent technologies have explored the potential of generative AI to promote civil discourse, encourage the development of mutual understanding in a discussion, produce feedback that enables people to converge in their views, and provide usable citizen input on policy questions posed to the public by governments and civil society. In this paper, we present a framework to help policymakers, technologists, and the public assess potential opportunities and risks when incorporating generative AI into online platforms for discussion and deliberation in order to strengthen democratic practices and help democratic governments make more effective and responsive policy decisions.",3
2018,"Social Media, Political Polarization, and Political Disinformation: A Review of the Scientific Literature","Joshua A. Tucker, Andrew Guess, Pablo
Barberá, Cristian Vaccari, Alexandra
Siegel, Sergey Sanovich, Denis Stukal,
and Brendan Nyhan",SSRN Electronic Journal,Social Science,"The following report is intended to provide an overview of the current state of the literature on the relationship between social media; political polarization; and political “disinformation,” a term used to encompass a wide range of types of information about politics found online, including “fake news,” rumors, deliberately factually incorrect information, inadvertently factually incorrect information, politically slanted information, and “hyperpartisan” news. The review of the literature is provided in six separate sections, each of which can be read individually but that cumulatively are intended to provide an overview of what is known—and unknown—about the relationship between social media, political polarization, and disinformation. The report concludes by identifying key gaps in our understanding of these phenomena and the data that are needed to address them.",1451
2024,Bootstrapping LLM-based Task-Oriented Dialogue Agents via Self-Talk,"Dennis Ulmer, Elman Mansimov, Kaixiang Lin, Justin Sun, Xibin Gao, Yi Zhang",ACL,NLP,"Large language models (LLMs) are powerful dialogue agents, but specializing them towards fulfilling a specific function can be challenging. Instructing tuning, i.e. tuning models on instruction and sample responses generated by humans (Ouyang et al., 2022), has proven as an effective method to do so, yet requires a number of data samples that a) might not be available or b) costly to generate. Furthermore, this cost increases when the goal is to make the LLM follow a specific workflow within a dialogue instead of single instructions. Inspired by the self-play technique in reinforcement learning and the use of LLMs to simulate human agents, we propose a more effective method for data collection through LLMs engaging in a conversation in various roles. This approach generates a training data via “self-talk” of LLMs that can be refined and utilized for supervised fine-tuning. We introduce an automated way to measure the (partial) success of a dialogue. This metric is used to filter the generated conversational data that is fed back in LLM for training. Based on our automated and human evaluations of conversation quality, we demonstrate that such self-talk data improves results. In addition, we examine the various characteristics that showcase the quality of generated dialogues and how they can be connected to their potential utility as training data.",20
2021,Towards Argument Mining for Social Good: A Survey,"Eva Maria Vecchi, Neele Falk, Iman Jundi, Gabriella Lapesa",ACL,NLP,"This survey builds an interdisciplinary picture of Argument Mining (AM), with a strong focus on its potential to address issues related to Social and Political Science. More specifically, we focus on AM challenges related to its applications to social media and in the multilingual domain, and then proceed to the widely debated notion of argument quality. We propose a novel definition of argument quality which is integrated with that of deliberative quality from the Social Science literature. Under our definition, the quality of a contribution needs to be assessed at multiple levels: the contribution itself, its preceding context, and the consequential effect on the development of the upcoming discourse. The latter has not received the deserved attention within the community. We finally define an application of AM for Social Good: (semi-)automatic moderation, a highly integrative application which (a) represents a challenging testbed for the integrated notion of quality we advocate, (b) allows the empirical quantification of argument/deliberative quality to benefit from the developments in other NLP fields (i.e. hate speech detection, fact checking, debiasing), and (c) has a clearly beneficial potential at the level of its societal thanks to its real-world application (even if extremely ambitious).",52
2024,Argument Quality Assessment in the Age of Instruction-Following Large Language Models,"Henning Wachsmuth, Gabriella Lapesa, Elena Cabrio, Anne Lauscher, Joonsuk Park, Eva Maria Vecchi, Serena Villata, Timon Ziegenbein",LREC,NLP,"The computational treatment of arguments on controversial issues has been subject to extensive NLP research, due to its envisioned impact on opinion formation, decision making, writing education, and the like. A critical task in any such application is the assessment of an argument’s quality - but it is also particularly challenging. In this position paper, we start from a brief survey of argument quality research, where we identify the diversity of quality notions and the subjectiveness of their perception as the main hurdles towards substantial progress on argument quality assessment. We argue that the capabilities of instruction-following large language models (LLMs) to leverage knowledge across contexts enable a much more reliable assessment. Rather than just fine-tuning LLMs towards leaderboard chasing on assessment tasks, they need to be instructed systematically with argumentation theories and scenarios as well as with ways to solve argument-related problems. We discuss the real-world opportunities and ethical issues emerging thereby.",5
2017,Computational Argumentation Quality Assessment in Natural Language,"Henning Wachsmuth, Nona Naderi, Yufang Hou, Yonatan Bilu, Vinodkumar Prabhakaran, Tim Alberdingk Thijm, Graeme Hirst, Benno Stein",EACL,NLP,"Research on computational argumentation faces the problem of how to automatically assess the quality of an argument or argumentation. While different quality dimensions have been approached in natural language processing, a common understanding of argumentation quality is still missing. This paper presents the first holistic work on computational argumentation quality in natural language. We comprehensively survey the diverse existing theories and approaches to assess logical, rhetorical, and dialectical quality dimensions, and we derive a systematic taxonomy from these. In addition, we provide a corpus with 320 arguments, annotated for all 15 dimensions in the taxonomy. Our results establish a common ground for research on computational argumentation quality assessment.",266
2012,A Corpus for Research on Deliberation and Debate,"Marilyn Walker, Jean Fox Tree, Pranav Anand, Rob Abbott, Joseph King",LREC,NLP,"Deliberative, argumentative discourse is an important component of opinion formation, belief revision, and knowledge discovery; it is a cornerstone of modern civil society. Argumentation is productively studied in branches ranging from theoretical artificial intelligence to political rhetoric, but empirical analysis has suffered from a lack of freely available, unscripted argumentative dialogs. This paper presents the Internet Argument Corpus (IAC), a set of 390,704 posts in 11,800 discussions extracted from the online debate site 4forums.com. A 2866 thread/130,206 post extract of the corpus has been manually sided for topic of discussion, and subsets of this topic-labeled extract have been annotated for several dialogic and argumentative markers: degrees of agreement with a previous post, cordiality, audience-direction, combativeness, assertiveness, emotionality of argumentation, and sarcasm. As an application of this resource, the paper closes with a discussion of the relationship between discourse marker pragmatics, agreement, emotionality, and sarcasm in the IAC corpus.",356
1997,PARADISE: A Framework for Evaluating Spoken Dialogue Agents,"Marilyn A. Walker, Diane J. Litman, Candace A. Kamm, Alicia Abella",ACL,NLP,"This paper presents PARADISE (PARAdigm
for Dialogue System Evaluation), a general
framework for evaluating spoken dialogue
agents. The framework decouples task requirements from an agent's dialogue behaviors, supports comparisons among dialogue strategies,
enables the calculation of performance over
subdialogues and whole dialogues, specifies
the relative contribution of various factors to
performance, and makes it possible to compare
agents performing different tasks by normalizing for task complexity.",1080
2023,Contextual Interaction for Argument Post Quality Assessment,"Yiran Wang, Xuanang Chen, Ben He, Le Sun",EMNLP,NLP,"Recently, there has been an increased emphasis on assessing the quality of natural language arguments. Existing approaches primarily focus on evaluating the quality of individual argument posts. However, they often fall short when it comes to effectively distinguishing arguments that possess a narrow quality margin. To address this limitation, this paper delves into two alternative methods for modeling the relative quality of different arguments. These approaches include: 1) Supervised contrastive learning that captures the intricate interactions between arguments. By incorporating this approach, we aim to enhance the assessment of argument quality by effectively distinguishing between arguments with subtle differences in quality. 2) Large language models (LLMs) with in-context examples that harness the power of LLMs and enrich them with in-context examples. Through extensive evaluation and analysis on the publicly available IBM-Rank-30k dataset, we demonstrate the superiority of our contrastive argument quality assessment approach over state-of-the-art baselines. On the other hand, while LLMs with in-context examples showcase a commendable ability to identify high-quality argument posts, they exhibit relatively limited efficacy in discerning between argument posts with a narrow quality gap.",4
2022,Toxicity Detection with Generative Prompt-based Inference,"Yau-Shian Wang, Yingshan Chang",Arxiv,NLP,"Due to the subtleness, implicity, and different possible interpretations perceived by different people, detecting undesirable content from text is a nuanced difficulty. It is a long-known risk that language models (LMs), once trained on corpus containing undesirable content, have the power to manifest biases and toxicity. However, recent studies imply that, as a remedy, LMs are also capable of identifying toxic content without additional fine-tuning. Prompt-methods have been shown to effectively harvest this surprising self-diagnosing capability. However, existing prompt-based methods usually specify an instruction to a language model in a discriminative way. In this work, we explore the generative variant of zero-shot prompt-based toxicity detection with comprehensive trials on prompt engineering. We evaluate on three datasets with toxicity labels annotated on social media posts. Our analysis highlights the strengths of our generative classification approach both quantitatively and qualitatively. Interesting aspects of self-diagnosis and its ethical implications are discussed.",31
1984,Models of Turn Taking in Conversational Interaction,"Thomas P. Wilson, John M. Wiemann, and Don H. Zimmerman","Journal of Language and Social
Psychology",Social Science,"The routine exchange of turns is a fundamental structural feature of conversational interaction. This paper reviews current attempts to understand the mechanisms by which turns are exchanged and considers three major approaches: stochastic models, signalling models, and sequential-production models. Conceptual and empirical strengths and limitations of each approach are examined, and it is suggested that a synthesis combining some ideas from the signalling approach with the sequential-production approach offers the greatest promise. Attention is directed to three major concepts: conversational events as resources; the functions of social organisational, relational, and sequential contexts in the management of turn taking; and the interactional construction of turns.",182
2020,What Changed Your Mind: The Roles of Dynamic Topics and Discourse in Argumentation Process,"Jichuan Zeng, Jing Li, Yulan He, Cuiyun Gao, Michael Lyu, Irwin King",The Web Conference 2020,Computer Science,"In our world with full of uncertainty, debates and argumentation contribute to the progress of science and society. Despite of the increasing attention to characterize human arguments, most progress made so far focus on the debate outcome, largely ignoring the dynamic patterns in argumentation processes. This paper presents a study that automatically analyzes the key factors in argument persuasiveness, beyond simply predicting who will persuade whom. Specifically, we propose a novel neural model that is able to dynamically track the changes of latent topics and discourse in argumentative conversations, allowing the investigation of their roles in influencing the outcomes of persuasion. Extensive experiments have been conducted on argumentative conversations on both social media and supreme court. The results show that our model outperforms state-of-the-art models in identifying persuasive arguments via explicitly exploring dynamic factors of topic and discourse. We further analyze the effects of topics and discourse on persuasiveness, and find that they are both useful — topics provide concrete evidence while superior discourse styles may bias participants, especially in social media arguments. In addition, we draw some findings from our empirical results, which will help people better engage in future persuasive conversations.",21
2017,Characterizing Online Discussion Using Coarse Discourse Sequences,"Amy Zhang,
Bryan Culbertson,
Praveen Paritosh
",AAAI,"Computer Science, NLP","In this work, we present a novel method for classifying comments in online discussions into a set of coarse discourse acts towards the goal of better understanding discussions at scale. To facilitate this study, we devise a categorization of coarse discourse acts designed to encompass general online discussion and allow for easy annotation by crowd workers. We collect and release a corpus of over 9,000 threads comprising over 100,000 comments manually annotated via paid crowdsourcing with discourse acts and randomly sampled from the site Reddit. Using our corpus, we demonstrate how the analysis of discourse acts can characterize different types of discussions, including discourse sequences such as Q&A pairs and chains of disagreement, as well as different communities. Finally, we conduct experiments to predict discourse acts using our corpus, finding that structured prediction models such as conditional random fields can achieve an F1 score of 75%. We also demonstrate how the broadening of discourse acts from simply question and answer to a richer set of categories can improve the recall performance of Q&A extraction.",125
2021,DynaEval: Unifying Turn and Dialogue Level Evaluation,"Chen Zhang, Yiming Chen, Luis Fernando D’Haro, Yan Zhang, Thomas Friedrichs, Grandee Lee, Haizhou Li",ACL,NLP,"A dialogue is essentially a multi-turn interaction among interlocutors. Effective evaluation metrics should reflect the dynamics of such interaction. Existing automatic metrics are focused very much on the turn-level quality, while ignoring such dynamics. To this end, we propose DynaEval, a unified automatic evaluation framework which is not only capable of performing turn-level evaluation, but also holistically considers the quality of the entire dialogue. In DynaEval, the graph convolutional network (GCN) is adopted to model a dialogue in totality, where the graph nodes denote each individual utterance and the edges represent the dependency between pairs of utterances. A contrastive loss is then applied to distinguish well-formed dialogues from carefully constructed negative samples. Experiments show that DynaEval significantly outperforms the state-of-the-art dialogue coherence model, and correlates strongly with human judgements across multiple dialogue evaluation aspects at both turn and dialogue level.",70
2023,xDial-Eval: A Multilingual Open-Domain Dialogue Evaluation Benchmark,"Chen Zhang, Luis D’Haro, Chengguang Tang, Ke Shi, Guohua Tang, Haizhou Li
",EMNLP,NLP,"Recent advancements in reference-free learned metrics for open-domain dialogue evaluation have been driven by the progress in pre-trained language models and the availability of dialogue data with high-quality human annotations. However, current studies predominantly concentrate on English dialogues, and the generalization of these metrics to other languages has not been fully examined. This is largely due to the absence of a multilingual dialogue evaluation benchmark. To address the issue, we introduce xDial-Eval, built on top of open-source English dialogue evaluation datasets. xDial-Eval includes 12 turn-level and 6 dialogue-level English datasets, comprising 14930 annotated turns and 8691 annotated dialogues respectively. The English dialogue data are extended to nine other languages with commercial machine translation systems. On xDial-Eval, we conduct comprehensive analyses of previous BERT-based metrics and the recently-emerged large language models. Lastly, we establish strong self-supervised and multilingual baselines. In terms of average Pearson correlations over all datasets and languages, the best baseline outperforms OpenAI’s ChatGPT by absolute improvements of 6.5% and 4.6% at the turn and dialogue levels respectively, albeit with much fewer parameters. The data and code are publicly available at https://github.com/e0397123/xDial-Eval.",7
2024,A comprehensive analysis of the effectiveness of large language models as automatic dialogue evaluators,"Chen Zhang, Luis Fernando D'Haro, Yiming Chen, Malu Zhang, Haizhou Li",AAAI,"Computer Science, NLP","Automatic evaluation is an integral aspect of dialogue system research. The traditional reference-based NLG metrics are generally found to be unsuitable for dialogue assessment. Consequently, recent studies have suggested various unique, reference-free neural metrics that better align with human evaluations. Notably among them, large language models (LLMs), particularly the instruction-tuned variants like ChatGPT, are shown to be promising substitutes for human judges. Yet, existing works on utilizing LLMs for automatic dialogue evaluation are limited in their scope in terms of the number of meta-evaluation datasets, mode of evaluation, coverage of LLMs, etc. Hence, it remains inconclusive how effective these LLMs are. To this end, we conduct a comprehensive study on the application of LLMs for automatic dialogue evaluation. Specifically, we analyze the multi-dimensional evaluation capability of 30 recently emerged LLMs at both turn and dialogue levels, using a comprehensive set of 12 meta-evaluation datasets. Additionally, we probe the robustness of the LLMs in handling various adversarial perturbations at both turn and dialogue levels. Finally, we explore how model-level and dimension-level ensembles impact the evaluation performance. All resources are available at https://github.com/e0397123/comp-analysis.",16